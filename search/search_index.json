{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introducing the Reliability Toolkit \"Resilience is a Verb\" - David D. Woods \"...Reliability is too.\" - ChaosIQ At ChaosIQ, we believe that reliability is a practice. That's why we founded the Chaos Toolkit free and open source project ecosystem, and now the Reliability Toolkit. Together the Reliability Toolkit, along with the Chaos Toolkit and a whole host of other tools you can pick from, provide a place to practice reliability where you and your team can work together on making your systems more reliable. Reliability is not something you have , it is something you do or, more accurately, something you practice . Here you will learn why practicing reliability is important, how to do it, what tools to select from to help build your own reliability toolbox, and most importantly how to prove and improve the reliability of your own systems. What is reliability? Reliability is measured from the perspective of your system's users . A system can be said to be reliable if its users rely on it and it meets their expectations. If this is the case, we often say that the users are happy with the system. If your users are happy with your system then it is not only continuing to evolve and provide the right features, and so becoming increasingly useful over time, but the system also meets its user's expectations and allows them to build trust and confidence in the system's operation. Reliability is a crucial differentiator if its users are to depend on the system. Successful systems are useful, performant and reliable. Reliability goes Beyond Testing for Release You could, and should, test your systems before release, building your own trust and confidence that what's being changed will work well according to your own measurements of success. In fact the adoption of Agile and DevOps practices, especially Continuous Delivery , only increases the emphasis on high quality testing of a set of changes is continually prepared and released to its users. Effective adoption of these practices goes hand-in-hand with practicing reliability. The challenge is that if a system is sufficiently complex, and most modern enterprise's systems are, then it is not possible to prove that a system will be reliable before it is run. No matter how much proof you have invested in obtaining prior to release, no matter how many unit, integration, feature and system tests you have conducted as part of your continuous integration and build, reliability can only be proved when the system is running, and ideally under realistic conditions. Is my system Reliable? Your system is reliable if it continues to meet its users expectations over time. Surprising conditions over time threaten your system's ability to meet those commitments and expectations, testing the efficacy of your system's robustness strategies. A robustness strategy is any strategy you've deliberately applied in the hope that it will help some aspect of your system better respond to some predicted conditions. For example, you might employ High Availability deployment options for your data storage, circuit breakers for inter-service communications, playbooks to help your people respond, dashboards and other observability tools to aid system comprehension, debugging and real-time alerting, even incident response systems to help your people synchronise and respond to surprising conditions. These are all robustness strategies as they help you respond to known threats to your system's reliability. Robustness strategies are applied across the whole of your socio-technical system, including the people, practices and processes that surround it. You aim to add the right mix of robustness strategies so that your socio-technical system is better prepared for known conditions. The better prepared the system, the better it will deal with anticipated conditions. That's the hope anyway. Of course there's also the unexpected conditions as well, and for those your robustness strategies have a positive impact on your system reliablility, but that is not guaranteed. There are three difficulties with robustness strategies. Firstly they can appear to be no-brainer techniques to apply everywhere, even where they will not help. The second problem is that robustness strategies are applied in the hope that they will respond appropriately to target conditions that you expect, or at least anticipate, but then those strategies are rarely verified to actually work the way you hope they will before real circumstances. On top of those, it is very rare that combinations of multiple robustness strategies working together to produce a positive result are ever proactively verified before they are needed for real. You hope they will work well, but hope is not the right strategy. Proactively Verifying Robustness helps Reliability with Chaos Engineering One of the key tasks when practicing reliability is exploring how effective your robustness strategies actually are when they are called upon to work together. You can verify how observable your system is, how your circuit breakers pop, and what the overall impact might be on your reliability objectives using the practice of chaos engineering. \"Chaos Engineering's sole purpose is to provide evidence of system weaknesses\" - \"Learning Chaos Engineering\" by Russ Miles, O'Reilly Media Using chaos engineering you can collect the evidence of the real impact on your system's reliability under adverse conditions. Rather than relying on hope, you build chaos engineering experiments that verify how your system employs its robustness strategies to anticipate, coordinate and respond to difficult conditions. Beyond Robustness: Resilience Robustness, and even verification using chaos engineering, is limited to helping you prove and improve how your system's reliability is affected in the face of known conditions. But what about the unknowns? While it's impossible to verify how your system will respond under any unknown conditions, this is where resilience engineering can help. Resilience engineering aims to help you develop your system so that it is \"poised to adapt\". By building specific capacities, your system can be ready to detect, deal and, more importantly learn from unexpected conditions. Those resilience capacities are manifested across your entire socio-technical system. Practicing Reliability & Resilience When you practice reliability you proactively prove and improve your organisation's resilience capacity to adapt to unexpected reliability threats. You and your team will invest in practices to develop capacities. To do this you will establish your own Reliability Toolbox and practices to help you explore and develop your system's ability to anticipate, synchronize, respond and generally adapt to unexpected conditions. Praciticing reliability brings together principles, tools and techniques from multiple sources including resilience engineering, site reliability engineering, DevOps, DevSecOps, effective operations, incident response, and system observability. You don't need to be an expert in any of these, but by beginning to practice reliability you will gradually adopt useful parts from each as you choose to invest the right amount of time and resources in developing your system's resilience.","title":"Introducing the Reliability Toolkit"},{"location":"#introducing-the-reliability-toolkit","text":"\"Resilience is a Verb\" - David D. Woods \"...Reliability is too.\" - ChaosIQ At ChaosIQ, we believe that reliability is a practice. That's why we founded the Chaos Toolkit free and open source project ecosystem, and now the Reliability Toolkit. Together the Reliability Toolkit, along with the Chaos Toolkit and a whole host of other tools you can pick from, provide a place to practice reliability where you and your team can work together on making your systems more reliable. Reliability is not something you have , it is something you do or, more accurately, something you practice . Here you will learn why practicing reliability is important, how to do it, what tools to select from to help build your own reliability toolbox, and most importantly how to prove and improve the reliability of your own systems.","title":"Introducing the Reliability Toolkit"},{"location":"#what-is-reliability","text":"Reliability is measured from the perspective of your system's users . A system can be said to be reliable if its users rely on it and it meets their expectations. If this is the case, we often say that the users are happy with the system. If your users are happy with your system then it is not only continuing to evolve and provide the right features, and so becoming increasingly useful over time, but the system also meets its user's expectations and allows them to build trust and confidence in the system's operation. Reliability is a crucial differentiator if its users are to depend on the system. Successful systems are useful, performant and reliable.","title":"What is reliability?"},{"location":"#reliability-goes-beyond-testing-for-release","text":"You could, and should, test your systems before release, building your own trust and confidence that what's being changed will work well according to your own measurements of success. In fact the adoption of Agile and DevOps practices, especially Continuous Delivery , only increases the emphasis on high quality testing of a set of changes is continually prepared and released to its users. Effective adoption of these practices goes hand-in-hand with practicing reliability. The challenge is that if a system is sufficiently complex, and most modern enterprise's systems are, then it is not possible to prove that a system will be reliable before it is run. No matter how much proof you have invested in obtaining prior to release, no matter how many unit, integration, feature and system tests you have conducted as part of your continuous integration and build, reliability can only be proved when the system is running, and ideally under realistic conditions.","title":"Reliability goes Beyond Testing for Release"},{"location":"#is-my-system-reliable","text":"Your system is reliable if it continues to meet its users expectations over time. Surprising conditions over time threaten your system's ability to meet those commitments and expectations, testing the efficacy of your system's robustness strategies. A robustness strategy is any strategy you've deliberately applied in the hope that it will help some aspect of your system better respond to some predicted conditions. For example, you might employ High Availability deployment options for your data storage, circuit breakers for inter-service communications, playbooks to help your people respond, dashboards and other observability tools to aid system comprehension, debugging and real-time alerting, even incident response systems to help your people synchronise and respond to surprising conditions. These are all robustness strategies as they help you respond to known threats to your system's reliability. Robustness strategies are applied across the whole of your socio-technical system, including the people, practices and processes that surround it. You aim to add the right mix of robustness strategies so that your socio-technical system is better prepared for known conditions. The better prepared the system, the better it will deal with anticipated conditions. That's the hope anyway. Of course there's also the unexpected conditions as well, and for those your robustness strategies have a positive impact on your system reliablility, but that is not guaranteed. There are three difficulties with robustness strategies. Firstly they can appear to be no-brainer techniques to apply everywhere, even where they will not help. The second problem is that robustness strategies are applied in the hope that they will respond appropriately to target conditions that you expect, or at least anticipate, but then those strategies are rarely verified to actually work the way you hope they will before real circumstances. On top of those, it is very rare that combinations of multiple robustness strategies working together to produce a positive result are ever proactively verified before they are needed for real. You hope they will work well, but hope is not the right strategy.","title":"Is my system Reliable?"},{"location":"#proactively-verifying-robustness-helps-reliability-with-chaos-engineering","text":"One of the key tasks when practicing reliability is exploring how effective your robustness strategies actually are when they are called upon to work together. You can verify how observable your system is, how your circuit breakers pop, and what the overall impact might be on your reliability objectives using the practice of chaos engineering. \"Chaos Engineering's sole purpose is to provide evidence of system weaknesses\" - \"Learning Chaos Engineering\" by Russ Miles, O'Reilly Media Using chaos engineering you can collect the evidence of the real impact on your system's reliability under adverse conditions. Rather than relying on hope, you build chaos engineering experiments that verify how your system employs its robustness strategies to anticipate, coordinate and respond to difficult conditions.","title":"Proactively Verifying Robustness helps Reliability with Chaos Engineering"},{"location":"#beyond-robustness-resilience","text":"Robustness, and even verification using chaos engineering, is limited to helping you prove and improve how your system's reliability is affected in the face of known conditions. But what about the unknowns? While it's impossible to verify how your system will respond under any unknown conditions, this is where resilience engineering can help. Resilience engineering aims to help you develop your system so that it is \"poised to adapt\". By building specific capacities, your system can be ready to detect, deal and, more importantly learn from unexpected conditions. Those resilience capacities are manifested across your entire socio-technical system.","title":"Beyond Robustness: Resilience"},{"location":"#practicing-reliability-resilience","text":"When you practice reliability you proactively prove and improve your organisation's resilience capacity to adapt to unexpected reliability threats. You and your team will invest in practices to develop capacities. To do this you will establish your own Reliability Toolbox and practices to help you explore and develop your system's ability to anticipate, synchronize, respond and generally adapt to unexpected conditions. Praciticing reliability brings together principles, tools and techniques from multiple sources including resilience engineering, site reliability engineering, DevOps, DevSecOps, effective operations, incident response, and system observability. You don't need to be an expert in any of these, but by beginning to practice reliability you will gradually adopt useful parts from each as you choose to invest the right amount of time and resources in developing your system's resilience.","title":"Practicing Reliability &amp; Resilience"},{"location":"objectives/","text":"A reliability objective is something in your System that you or your customers care about and which shows that your system or part of your system is available. In Site Reliability Engineering (SRE) terms this is a Service Level Objective (SLO). You might care that your homepage is available 99.9% of the time. You might care that your database is able to respond to a particular query under an amount of time. Or you might care that your users can interact with your system, perform some system function, 99.999% of the time as it\u2019s super-critical! These are all Objectives, and they frame what\u2019s important to you about your system. A good set of Objectives represents a great high-level description of how your system aims to behave, from your perspective, in order to make your users happy. You create an Objective from the Objectives page and click the Create a New Objective button. If you don't currently have a team selected you will have to select a team to associate this objective with. On the Objective form specify an Objective you care about for your system. First, you need to add a meaningful name for your Objective. An objective's name should mean something of value to the business or your customers. You can also add an optional description to elaborate on your Objective. You can optionally add a tag to your Objective. Tags are used to filter for your objective when you are managing many Objectives. You now specify the most important part of your objective which is a target percentage availability over a specified period, an example could be 99.5% available, over a period of 7 days. The target availability is less than 100% so this leaves a margin for error, this can be considered the Error Budget. The next step is to identify how you would measure your Objective. This is something in your that you can measure that is an indicator that the system is meeting its objectives.","title":"Objectives"},{"location":"running-on-ci-cd/","text":"As part of managing your system objectives, you have identified verifications that you can run that will measure the health of your system. When running CI/CD you are trying to deliver fast and often, some errors could slip through. So it makes sense to run you verifications as part of the Continuous Delivery pipeline. There are many options for running CI/CD, at the moment this section only covers Travis, but we will be expanding on that list.","title":"Running Continuous Verifications"},{"location":"timeline/","text":"The Timeline is a view to see in one place all the events that have happened to the users system over time. Any event could have an impact on the reliability of the system. A User can observe and understand the impact events have had on their system. This helps them understand the nature of these disturbances and the event that caused the disturbance.","title":"Timeline"},{"location":"deployment-options/deployment-options/","text":"You can choose from three options for your deployment of ChaosIQ, depending on your subscription plan: ChaosIQ SaaS ChaosIQ Single-Tenant ChaosIQ Self-Hosted ChaosIQ SaaS In the early days of the free and open source Chaos Toolkit we knew that chaos experiments themselves had to executed and, more importantly, controlled \"in-house\". That was one of the motivating factors in the Chaos Toolkit's design: a simple CLI that you could use locally as easily as possible to explore how to do chaos engineering right with an emphasis on experiments. The Chaos Toolkit is still the open core of ChaosIQ and we remain as dedicated as ever to working closely with the whole community to make the toolkit as powerful as possible. At the same time, ChaosIQ is designed with a different, extended goal in mind. The Chaos Toolkit is specifically designed to help individuals and organizations write and execute powerful and customizable chaos engineering experiments. Whereas ChaosIQ is designed to help organisations scale out chaos engineering and system verification across all their teams. For this reason ChaosIQ provides a cross-organizational experience that include capabilities such as Safeguards , centralised dashboards and the authoring and execution of system verifications. All of this is provided in the first instance as a Software as a Service (SaaS), hosted by ChaosIQ on our own systems. The actual chaos engineering experiments, and system verifications, are still executed locally by the Chaos Toolkit, which is extended to add some of these capabilities including the ability to talk back to ChaosIQ: SaaS is the default deployment option for ChaosIQ. We host the SaaS, you run the ChaosIQ-extended Chaos Toolkit wherever you want. For those that don't want outside entities, such as ChaosIQ, to be instigating conditions in their systems, this model still fits as we don't, by default, instigate any experiments or verifications that you don't trigger yourself through the chaos run or chaos verify commands. One advantage of this approach is that you get the simplest and most friendly billing plan (more clarity on our pricing is coming in a future article) that is perfect (and, we're told, fair) for individuals as well as small and large organizations. One requirement though is that some data is pushed back to ChaosIQ so that it can apply features like Safeguards, Dashboards and Reliability Insights. For many, many customers this is a workable constraint but for those that need something different, we support two further deployment options: Single-Tenant and Self-Hosted. The Single-Tenant SaaS Option Some organizations don't want any of their data to even reside, regardless of how temporarily, on any systems that might contain other people's data. They might also need to make sure their ChaosIQ system is in a specific geography. However, they also don't need to run ChaosIQ themselves. For these customers, we provide the \"Single-Tenant\" deployment option: The Single-Tenant deployment option gives our customers all the features of ChaosIQ on their own, dedicated SaaS instances, often in their own preferred geography and/or on a preferred cloud provider, and still managed and supported by ChaosIQ. We keep single-tenant deployments constantly up-to-date with our multi-tenant SaaS and so there is no difference in the overall experience. The final category of users are those that really want to run ChaosIQ within their own organizational boundaries, however they choose to define those. In this specific case they opt for our \"Self Hosted\" deployment option. The Self-Hosted Option Self Hosted is often referred to as \"On Premise\" or an \"Enterprise Option\", although it really means that the customer has to meet the requiremenjt of running anything involved in system verification and chaos engineering, in any capacity, within and on their own systems: For these customers we provide auto-updates to their hosted ChaosIQ systems that mean they keep as up-to-date as they choose with the ChaosIQ-hosted SaaS while running our packaged software systems within their own world. What about customisation options? All of the three deployment options, from SaaS, Single-Tennant SaaS through to Self-Hosted, offers powerful features for customisation. Whether it be integrating experiments and verifications with your own systems, or building unique safeguards, the Chaos Toolkit was built with customisation in mind, and ChaosIQ leverage and contribute to that as well. By their nature, Self-Hosted deployments sometimes require more bespoke customisations with your systems and so part of the plan for those customers is to be able to opt for custom development from our ChaosIQ Special Ops team. Picking from the options Picking from one of the three options is as simple as: Do you absolutely need to run ChaosIQ for yourself? -> Talk to us about \"ChaosIQ Self-Hosted\" Do you need to have your own, dedicated ChaosIQ, possibly run in a specific geography or with a specific cloud provider, but you're happy that it is still managed and maintained by ChaosIQ? -> Talk to us about \"ChaosIQ Single-Tenant\" Do you want to use the most cost-effective and flexible option? -> Sign-up to the ChaosIQ SaaS","title":"Deployment Options"},{"location":"deployment-options/deployment-options/#chaosiq-saas","text":"In the early days of the free and open source Chaos Toolkit we knew that chaos experiments themselves had to executed and, more importantly, controlled \"in-house\". That was one of the motivating factors in the Chaos Toolkit's design: a simple CLI that you could use locally as easily as possible to explore how to do chaos engineering right with an emphasis on experiments. The Chaos Toolkit is still the open core of ChaosIQ and we remain as dedicated as ever to working closely with the whole community to make the toolkit as powerful as possible. At the same time, ChaosIQ is designed with a different, extended goal in mind. The Chaos Toolkit is specifically designed to help individuals and organizations write and execute powerful and customizable chaos engineering experiments. Whereas ChaosIQ is designed to help organisations scale out chaos engineering and system verification across all their teams. For this reason ChaosIQ provides a cross-organizational experience that include capabilities such as Safeguards , centralised dashboards and the authoring and execution of system verifications. All of this is provided in the first instance as a Software as a Service (SaaS), hosted by ChaosIQ on our own systems. The actual chaos engineering experiments, and system verifications, are still executed locally by the Chaos Toolkit, which is extended to add some of these capabilities including the ability to talk back to ChaosIQ: SaaS is the default deployment option for ChaosIQ. We host the SaaS, you run the ChaosIQ-extended Chaos Toolkit wherever you want. For those that don't want outside entities, such as ChaosIQ, to be instigating conditions in their systems, this model still fits as we don't, by default, instigate any experiments or verifications that you don't trigger yourself through the chaos run or chaos verify commands. One advantage of this approach is that you get the simplest and most friendly billing plan (more clarity on our pricing is coming in a future article) that is perfect (and, we're told, fair) for individuals as well as small and large organizations. One requirement though is that some data is pushed back to ChaosIQ so that it can apply features like Safeguards, Dashboards and Reliability Insights. For many, many customers this is a workable constraint but for those that need something different, we support two further deployment options: Single-Tenant and Self-Hosted.","title":"ChaosIQ SaaS"},{"location":"deployment-options/deployment-options/#the-single-tenant-saas-option","text":"Some organizations don't want any of their data to even reside, regardless of how temporarily, on any systems that might contain other people's data. They might also need to make sure their ChaosIQ system is in a specific geography. However, they also don't need to run ChaosIQ themselves. For these customers, we provide the \"Single-Tenant\" deployment option: The Single-Tenant deployment option gives our customers all the features of ChaosIQ on their own, dedicated SaaS instances, often in their own preferred geography and/or on a preferred cloud provider, and still managed and supported by ChaosIQ. We keep single-tenant deployments constantly up-to-date with our multi-tenant SaaS and so there is no difference in the overall experience. The final category of users are those that really want to run ChaosIQ within their own organizational boundaries, however they choose to define those. In this specific case they opt for our \"Self Hosted\" deployment option.","title":"The Single-Tenant SaaS Option"},{"location":"deployment-options/deployment-options/#the-self-hosted-option","text":"Self Hosted is often referred to as \"On Premise\" or an \"Enterprise Option\", although it really means that the customer has to meet the requiremenjt of running anything involved in system verification and chaos engineering, in any capacity, within and on their own systems: For these customers we provide auto-updates to their hosted ChaosIQ systems that mean they keep as up-to-date as they choose with the ChaosIQ-hosted SaaS while running our packaged software systems within their own world.","title":"The Self-Hosted Option"},{"location":"deployment-options/deployment-options/#what-about-customisation-options","text":"All of the three deployment options, from SaaS, Single-Tennant SaaS through to Self-Hosted, offers powerful features for customisation. Whether it be integrating experiments and verifications with your own systems, or building unique safeguards, the Chaos Toolkit was built with customisation in mind, and ChaosIQ leverage and contribute to that as well. By their nature, Self-Hosted deployments sometimes require more bespoke customisations with your systems and so part of the plan for those customers is to be able to opt for custom development from our ChaosIQ Special Ops team.","title":"What about customisation options?"},{"location":"deployment-options/deployment-options/#picking-from-the-options","text":"Picking from one of the three options is as simple as: Do you absolutely need to run ChaosIQ for yourself? -> Talk to us about \"ChaosIQ Self-Hosted\" Do you need to have your own, dedicated ChaosIQ, possibly run in a specific geography or with a specific cloud provider, but you're happy that it is still managed and maintained by ChaosIQ? -> Talk to us about \"ChaosIQ Single-Tenant\" Do you want to use the most cost-effective and flexible option? -> Sign-up to the ChaosIQ SaaS","title":"Picking from the options"},{"location":"faq/plugin/","text":"How do I check I have the latest version of the ChaosIQ plugin? To connect the Chaos Toolkit to ChaosIQ you need to install and run the chaosiq-cloud plugin . The plugin is added to the python environment where you run the Chaos Toolkit, so navigate to you terminal window where you have the Chaos Toolkit setup, and enter: $ pip search 'chaosiq' chaosiq-cloud ( 0 .10.0 ) - ChaosIQ plugin for the Chaos Toolkit CLI INSTALLED: 0 .9.0 LATEST: 0 .10.0 The output shows in this case version 0.9.0 of the chaosiq-cloud is installed and the latest version is 0.10.0. Normally you would expect to be using the latest version if you want to install the latest version enter: pip install --upgrade chaosiq-cloud The command will output a lot of dependency information for the chaosiq-cloud package, which is omitted for brevity, but it will finish with the following text: Installing collected packages: chaosiq-cloud Attempting uninstall: chaosiq-cloud Found existing installation: chaosiq-cloud 0 .9.0 Uninstalling chaosiq-cloud-0.9.0: Successfully uninstalled chaosiq-cloud-0.9.0 Successfully installed chaosiq-cloud-0.10.0 This shows the package has now been installed with the latest version.","title":"How do I check I have the latest version of the ChaosIQ plugin"},{"location":"faq/plugin/#how-do-i-check-i-have-the-latest-version-of-the-chaosiq-plugin","text":"To connect the Chaos Toolkit to ChaosIQ you need to install and run the chaosiq-cloud plugin . The plugin is added to the python environment where you run the Chaos Toolkit, so navigate to you terminal window where you have the Chaos Toolkit setup, and enter: $ pip search 'chaosiq' chaosiq-cloud ( 0 .10.0 ) - ChaosIQ plugin for the Chaos Toolkit CLI INSTALLED: 0 .9.0 LATEST: 0 .10.0 The output shows in this case version 0.9.0 of the chaosiq-cloud is installed and the latest version is 0.10.0. Normally you would expect to be using the latest version if you want to install the latest version enter: pip install --upgrade chaosiq-cloud The command will output a lot of dependency information for the chaosiq-cloud package, which is omitted for brevity, but it will finish with the following text: Installing collected packages: chaosiq-cloud Attempting uninstall: chaosiq-cloud Found existing installation: chaosiq-cloud 0 .9.0 Uninstalling chaosiq-cloud-0.9.0: Successfully uninstalled chaosiq-cloud-0.9.0 Successfully installed chaosiq-cloud-0.10.0 This shows the package has now been installed with the latest version.","title":"How do I check I have the latest version of the ChaosIQ plugin?"},{"location":"gettingstarted/first-objective/","text":"Ensure you have a team selected using the drop-down at the to left of the ChaosIQ console. Then navigate to the Objectives page and click the Create a New Objective button. On the Objective form specify an Objective you care about for your system. First you need to add a meaningful name for your Objective. An objective's name should mean something of value to the business or the your customers. You can also add an optional description to elaborate on your Objective. You can optionally add a tag to your Objective. Tags are used to filter for your objective when you are managing many Objectives. You now specify the most important part of your objective which is a target percentage availability over a specified period, an example could be 99.5% available, over a period of 7 days. The target availability is less than 100% so this leaves a margin for error, this can be considered the Error Budget. The next step is to identify how you would measure your Objective. This is something in your that you can measure that is an indicator that the system is meeting its objectives. In ChaosIQ, select the drop-down menu for the type of measurement. Note Currently there are a limited number of options for the type of measurement but these should expand over time as ChaosIQ evolves. Select a measure from the drop-down such as HTTP status code . The fields displayed on the Create Objective form will dynamically update depending on the drop-down field you have selected. For HTTP status code you will be able to enter a URL you are going to probe and a tolerance for that probe. The tolerance can be either HTTP Status Code Check where you will specify an explicit expected status code as a response. Alternatively, you could select a range of HTTP Status codes, where you specify a lower and upper bound for the expected response code. Having identified how you are going to measure your objective select the Create Objective and Verify It button to complete your objective and it will take you to the Create a Verification form.","title":"Create your first Objective"},{"location":"gettingstarted/first-verification/","text":"First you need to indicate what objective this verification is being built for. An objective may be pre-selected, or you will need to select the objective from the drop-down list. Then you will enter a frequency in seconds and over what duration your verification will be run. The values chosen on these fields impact your usage footprint in ChaosIQ so a high usage warning may be displayed. Next you will select and specify the conditions you want to apply as part of your verification. The first option is to apply No Condition, this means you are going to measure you verification but you are not going to apply an adverse effect as part of your Verification. This is a good case for a control Verification as it establishes how the Verification performs in normal conditions. In this case leave the condition as No Condition and select the Create Verification and View Execution Steps button to on to the Run your Verification page. Finally you are prompted to give your verification a name that reflects what this Verification is going to do. Based on the objective you are verifying, and the conditions that you selected, a name for your new verification will have been created and suggested for you. If you prefer you can override this suggestion with a name of your own. An example could be is Ensure My Service remains available when a Web Service POD restarts.","title":"Create your first Verification"},{"location":"gettingstarted/introduction/","text":"This document will show you the steps to run your first Verification with the Chaos Toolkit and publish the results to ChaosIQ. The workflow in ChaosIQ is organized around Objectives and Verifications . Objectives identify the parts of your system that you care about and are highly related to what keeps your users happy. Verifications explore the impact on your objectives under various conditions, such as failures. We will go through the steps required to get your first Verification running and published into ChaosIQ: Prerequisites . Login to ChaosIQ . Sign-in Chaos Toolkit to ChaosIQ . Create your first Objective . Create your first Verification . Run your first Verification .","title":"Introduction"},{"location":"gettingstarted/login-chaosiq/","text":"When you open https://console.chaosiq.io in your browser you will be presented with the ChaosIQ login page: When you select your preferred authentication provider you will be prompted for the required authentication details. Once you have authenticated you will be presented with the ChaosIQ Welcome page: You can enter your preferred email address at this point, this can be different from the email address provided by the authentication provider. You are also asked to accept ChaosIQ terms of Service and give ChaosIQ permission to store your data. You will then be asked to choose a plan, ChaosIQ are currently only offering the Early Access Plan (more plans will follow): Normally at this point users subscribe and create an Organization and teams to start using the ChaosIQ tools. If you select Subscribe Now you will be prompted for an Organization name: Note You can optionally to skip this stage for now, if you do so see Skipping subscription . Enter an Organization name, the Organization name has to be unique, it can't be one that has been used before within ChaosIQ. You will then be asked to create a team. Teams are where your Objectives are defined and where Chaos Experiments are run. It can represent a real-life team, or a specific project or system Once you have created the team name you will be taken to your teams start page where you can go on to create your first objective . That\u2019s it! You have authenticated and logged in to ChaosIQ, you have created your Organization and a Team you are all set to start using the ChaosIQ tools. Skipping subscription If you selected to Skip this at the subscribe stage you will be taken to the ChaosIQ start page: You have a number of choices from here, including links to articles, links to the ChaosIQ documentation and a useful video on Verification workflow. If you select Create an Organization, you will then be taken back to the Subscribe page.","title":"Login to ChaosIQ"},{"location":"gettingstarted/login-chaosiq/#skipping-subscription","text":"If you selected to Skip this at the subscribe stage you will be taken to the ChaosIQ start page: You have a number of choices from here, including links to articles, links to the ChaosIQ documentation and a useful video on Verification workflow. If you select Create an Organization, you will then be taken back to the Subscribe page.","title":"Skipping subscription"},{"location":"gettingstarted/prerequisites/","text":"ChaosIQ Prerequisites Before getting started with running your first Verification with the Chaos Toolkit and publish the results to ChaosIQ, some prerequisite steps are required. We will go through the prerequisite steps so you are ready to get your first Verification running and published into ChaosIQ: Install the Chaos Toolkit . Add the ChaosIQ Plugin . Access to ChaosIQ . If you\u2019ve already got a working installation of the Chaos Toolkit CLI then you can skip directly to Add the ChaosIQ Plugin Creating a new Chaos Toolkit CLI Installation using pip The Chaos Toolkit CLI is implemented in Python 3 and so needs a working Python installation at version 3.5+. When you execute the python3 command on your machine you see something like the following then you are all set: $ python3 --version Python 3.7.6 If you see a version lower than 3.5 then you\u2019ll first need to install a later version of Python. This is well documented on the Chaos Toolkit install page Create a Python Virtual Environment Dependencies can be installed for your Python installation through pip and it\u2019s often a good idea to create a Python Virtual Environment to contain your Chaos Toolkit CLI installation libraries. To create a Python virtual environment called chaostk execute the following: python3 -m venv ~/.venvs/chaostk Now you can activate your virtual environment by executing: $ source ~/.venvs/chaostk/bin/activate (chaostk) $ Tip You may want to use virtualenvwrapper to make this process much nicer. Install the Chaos Toolkit CLI using pip You install the Chaos Toolkit CLI as the Python chaostoolkit module into your virtual environment by using pip: (chaostk) $ pip install chaostoolkit You can verify the Chaos Toolkit CLI was installed by running: (chaostk) $ chaos --version chaos, version 1.4.1 Add the ChaosIQ Plugin to your Chaos Toolkit In order for the Chaos Toolkit to communicate with ChaosIQ you need to add the chaosiq-cloud plugin to your Chaos Toolkit installation. The chaosiq-cloud plugin is a Python package and can be found in the Python Package Index (PyPI) chaosiq-cloud . The ChaosIQ features can be added to your Chaos Toolkit CLI installation by executing: ( chaostk ) $ pip install chaosiq-cloud Access to ChaosIQ The next thing you will need is access to ChaosIQ. You will need access to https://console.chaosiq.io . This link should take you to the login page: Authentication Currently ChaosIQ supports two authentication providers Github and Google, so you will need either a Google account or a Github account, that you can use. This is really only required for the authentication step, after you login you can change the email address you wish to use and create your organization as required. That\u2019s it! You\u2019ve got a working installation of the Chaos Toolkit CLI and the chaosiq-cloud plugin installed. You have access to ChaosIQ and hopefully have a Github or Google account that you can authenticate with. The next step is Login to ChaosIQ .","title":"Prerequisites"},{"location":"gettingstarted/prerequisites/#chaosiq-prerequisites","text":"Before getting started with running your first Verification with the Chaos Toolkit and publish the results to ChaosIQ, some prerequisite steps are required. We will go through the prerequisite steps so you are ready to get your first Verification running and published into ChaosIQ: Install the Chaos Toolkit . Add the ChaosIQ Plugin . Access to ChaosIQ . If you\u2019ve already got a working installation of the Chaos Toolkit CLI then you can skip directly to Add the ChaosIQ Plugin","title":"ChaosIQ Prerequisites"},{"location":"gettingstarted/prerequisites/#creating-a-new-chaos-toolkit-cli-installation-using-pip","text":"The Chaos Toolkit CLI is implemented in Python 3 and so needs a working Python installation at version 3.5+. When you execute the python3 command on your machine you see something like the following then you are all set: $ python3 --version Python 3.7.6 If you see a version lower than 3.5 then you\u2019ll first need to install a later version of Python. This is well documented on the Chaos Toolkit install page","title":"Creating a new Chaos Toolkit CLI Installation using pip"},{"location":"gettingstarted/prerequisites/#create-a-python-virtual-environment","text":"Dependencies can be installed for your Python installation through pip and it\u2019s often a good idea to create a Python Virtual Environment to contain your Chaos Toolkit CLI installation libraries. To create a Python virtual environment called chaostk execute the following: python3 -m venv ~/.venvs/chaostk Now you can activate your virtual environment by executing: $ source ~/.venvs/chaostk/bin/activate (chaostk) $ Tip You may want to use virtualenvwrapper to make this process much nicer.","title":"Create a Python Virtual Environment"},{"location":"gettingstarted/prerequisites/#install-the-chaos-toolkit-cli-using-pip","text":"You install the Chaos Toolkit CLI as the Python chaostoolkit module into your virtual environment by using pip: (chaostk) $ pip install chaostoolkit You can verify the Chaos Toolkit CLI was installed by running: (chaostk) $ chaos --version chaos, version 1.4.1","title":"Install the Chaos Toolkit CLI using pip"},{"location":"gettingstarted/prerequisites/#add-the-chaosiq-plugin-to-your-chaos-toolkit","text":"In order for the Chaos Toolkit to communicate with ChaosIQ you need to add the chaosiq-cloud plugin to your Chaos Toolkit installation. The chaosiq-cloud plugin is a Python package and can be found in the Python Package Index (PyPI) chaosiq-cloud . The ChaosIQ features can be added to your Chaos Toolkit CLI installation by executing: ( chaostk ) $ pip install chaosiq-cloud","title":"Add the ChaosIQ Plugin to your Chaos Toolkit"},{"location":"gettingstarted/prerequisites/#access-to-chaosiq","text":"The next thing you will need is access to ChaosIQ. You will need access to https://console.chaosiq.io . This link should take you to the login page:","title":"Access to ChaosIQ"},{"location":"gettingstarted/prerequisites/#authentication","text":"Currently ChaosIQ supports two authentication providers Github and Google, so you will need either a Google account or a Github account, that you can use. This is really only required for the authentication step, after you login you can change the email address you wish to use and create your organization as required. That\u2019s it! You\u2019ve got a working installation of the Chaos Toolkit CLI and the chaosiq-cloud plugin installed. You have access to ChaosIQ and hopefully have a Github or Google account that you can authenticate with. The next step is Login to ChaosIQ .","title":"Authentication"},{"location":"gettingstarted/run-first-verification/","text":"ChaosIQ will display the Run Verification page showing the Chaos Verify command with a URL selecting you Verification. To run the Verification select the Copy button, which will capture the command in your clipboard. Open the terminal window where you set-up your Chaos Toolkit and paste in the Chaos Verify command and select enter to run it. The command should run the Verification and publish the results to ChaosIQ. If you go to the Verifications page and select your Verification, you should be able to see the current state of the Verification. The Insights page will give you a view of your Verifications that have completed. This will give you an indication of the timeline of the Verification and a view of the events that occurred when the Verification was running. It is from the insights page that you should be able to learn the impact of your Verification and determine what actions are required. To view, the results select the Insights menu option. That's your first Verification created, run and published to ChaosIQ. The results are now made available on the Insights page. From the Insights page you can select the Details button and you can see the details view of the insight. The details view includes information about the Objective, the Measurement used and the Verification. It shows the Verification Run Timeline that includes a timeline chart of samples. Next steps are to add Conditions to your Verification to see what, if any, impact this might have on your Objective.","title":"Run your first Verification"},{"location":"gettingstarted/signin/","text":"So that your Chaos Toolkit installation can communicate with ChaosIQ, you need to set up your credentials using the chaos signin command. First generate a token from the ChaosIQ Tokens tab. The details for generating tokens are covered in the Tokens section Use the chaos signin command to connect to ChaosIQ and add your token. When the chaos signin command prompts for the token, paste the token from your clipboard: (chaostk) $ chaos signin ChaosIQ Cloud url [https://console.chaosiq.io]: ChaosIQ Cloud token: Experiments and executions will be published to organization 'MyName' ChaosIQ Cloud details saved at ~/.chaostoolkit/settings.yaml Your Chaos toolkit will now publish executions to ChaosIQ.","title":"Sign-in Chaos Toolkit to ChaosIQ"},{"location":"organizations-and-teams/create-organization/","text":"An organization is created when a person signs in to ChaosIQ without having been previously invited to join an organization.","title":"Creating an Organization"},{"location":"organizations-and-teams/creating-a-team/","text":"You can create an unlimited number of teams in your organization. Teams can be used to gather real-life teams or members of different teams working on common projects. They are a flexible model that should be able to fit the way you and your teammates want to work. Opening the Teams dropdown in the top-left corner of the window will list your available teams as well as allow you to create a new one. Click the Add a team button. On the Create a new Team page, you are asked to choose a name for your organization. When you are happy with your team name, click the Create Team button. A message will appear, telling you your organization was successfully created. This new organization is now listed in the top-left Teams menu. Clicking on its name will take you to the new teams' Objectives. Alternatively, you can use the Teams link in the top menu to view a list of the organizations you belong too and create new ones. Adding members to a team In a team view, click on the People link in the sidebar menu to display the list of all this team's members. Click on the Add members button to display a list of all people that can be added to this team (they are the people in your organization that are not yet members of this team).","title":"Creating a Team"},{"location":"organizations-and-teams/creating-a-team/#adding-members-to-a-team","text":"In a team view, click on the People link in the sidebar menu to display the list of all this team's members. Click on the Add members button to display a list of all people that can be added to this team (they are the people in your organization that are not yet members of this team).","title":"Adding members to a team"},{"location":"organizations-and-teams/invite-to-an-organization/","text":"From the organization view, click on the People link in the sidebar to display a list of the members of your organization. Click on the Invite people button to invite people to join the organization. Enter a comma-separated Email list and invites will be sent when you select the Send Invites button. Joining an organization When you have been invited to join an organization, signing in to ChaosIQ will automatically make you a member of this organization.","title":"Inviting people to your Organization"},{"location":"organizations-and-teams/invite-to-an-organization/#joining-an-organization","text":"When you have been invited to join an organization, signing in to ChaosIQ will automatically make you a member of this organization.","title":"Joining an organization"},{"location":"organizations-and-teams/organizations-and-teams-intro/","text":"Introduction to Organizations and Teams A system's resilience is rarely the responsibility of a single person. Even if you are someone whose job title explicitly mentions resilience, resilience is a cross-socio-technical system goal. Everyone should be aware of the system's objectives and how, and when, those objectives are being verified using ChaosIQ, so that's why we support the familiar setup of Organizations and Teams to help everyone organize their efforts. Organizations allow a high-level view of everything that is happening. Most of the time, your organization in ChaosIQ will represent your real-life organization or company. In your organization view, you can get a list of all objectives and verifications ever run and pushed to ChaosIQ. Teams are where the work happens. They are shared workspaces where people can collaborate on objectives, verifications, insights and even see the activity on action items.","title":"Introduction"},{"location":"organizations-and-teams/organizations-and-teams-intro/#introduction-to-organizations-and-teams","text":"A system's resilience is rarely the responsibility of a single person. Even if you are someone whose job title explicitly mentions resilience, resilience is a cross-socio-technical system goal. Everyone should be aware of the system's objectives and how, and when, those objectives are being verified using ChaosIQ, so that's why we support the familiar setup of Organizations and Teams to help everyone organize their efforts. Organizations allow a high-level view of everything that is happening. Most of the time, your organization in ChaosIQ will represent your real-life organization or company. In your organization view, you can get a list of all objectives and verifications ever run and pushed to ChaosIQ. Teams are where the work happens. They are shared workspaces where people can collaborate on objectives, verifications, insights and even see the activity on action items.","title":"Introduction to Organizations and Teams"},{"location":"organizations-and-teams/publishing-to-a-team/","text":"For Chaos Toolkit to send Verifications and Executions data to a team, you must have the ChaosIQ Cloud extension installed. $ pip install -U chaosiq-cloud Then, sign in to ChaosIQ $ chaos signin You will be asked the URL of ChaosIQ. It defaults to https://console.chaosiq.io, for SaaS users. If you use an an alternative deployment, change it to your URL and your choice will be remembered next time you sign in. ChaosIQ then asks for a token to identify you. To generate a new token, click on the Tokens link from the top menu. Click on Generate a Token to create a new token. Once you have chosen a name for your token, click on the Generate Token button. A message is displayed with your token. Copy it, then switch back to your terminal and paste it. Chaos Toolkit will then retrieve the list of organizations you belong to and asks you to choose which one you will publish to. If you only belong to one organization, ChaosIQ will skip this step. You are then asked to select which team you want to publish your experiments to. Select the one you want, and you are ready to run experiments. If you run an experiment with the chaos run command, it will now be published to ChaosIQ and available on the Executions page.","title":"Publishing Verifications to a Team"},{"location":"organizations-and-teams/switching-organizations/","text":"If you want to select a team from another organizations, use the chaos org command and you will be asked to select an organization and a team.","title":"Switching Organizations"},{"location":"organizations-and-teams/switching-teams/","text":"Run the chaos team command again to be able to choose a new default team to publish to.","title":"Switching Teams"},{"location":"reliability-workflow/reliability-workflow/","text":"The ChaosIQ Reliability Workflow ChaosIQ provides a Reliability Workflow. The Reliability Workflow\u2019s job is to help you proactively verify your system to gain insights into its reliability so that you can then prioritize and track work on improving that reliability alongside the regular work that you need to do on features. There are lots of good reasons to verify your system. You might be worried about surprise downtime and looking to try to anticipate and prepare better for incidents. You might also be curious as to how your system might respond to challenging conditions, and want to explore that before your users do. In a nutshell you want to verify your system because you care about your users\u2019 experience, and specifically about the reliability of that experience. With ChaosIQ, the goal of system verification is not only to show the impact that various conditions might have on your users happiness but to also turn those insights into prioritized, meaningful actions for improving a system's reliability. ChaosIQ brings this System Reliability Workflow to life with Objectives, Verifications, Insights and Action Items: Objectives and Measurements Objectives are literally things you care about. If you care about it, and can measure it, then it\u2019s an objective. You might care that your homepage is available 99.9% of the time. You might care that your database is able to respond to a particular query under an amount of time. Or you might care that your users can interact with your system, perform some system function, 99.999% of the time as it\u2019s super-critical! These are all Objectives, and they frame what\u2019s important to you about your system. A good set of Objectives represents a great high-level description of how your system aims to behave, from your perspective, in order to make your users happy. However, an Objective is not particularly useful unless it can be measured. Objectives can be measured in lots of different ways, often in combination, to give you some confidence that an Objective, at a given moment, is being met: The job of a measurement, or combination of measurements, is to be able provide a sample, an event, that is either \"successful\" or \"failing\" at a given moment in time. For example, you might measure that the response time for your homepage is within a tolerable time bracket at a given moment and, if it is within that tolerance, then it is a \"successful\" sample event. If the measurement shows that the homepage URL does not respond in the tolerated time, then the sample event would be designated \"failed\": The combination of Objectives and their corresponding measurements provides a shared understanding of how your system needs to behave in order to keep your users happy. This is the all-important framing necessary to then decide what you want to verify in order to see how your Objectives, and your users\u2019 happiness, is affected by your system\u2019s behavior under various conditions. TBD link to where you can define objectives in the Getting Started. Verifications Verifying an Objective helps you build trust and confidence in how your system will behave under a set of interesting conditions. Those conditions could be behavior such as security intrusions, infrastructure failures, platform failures, application failures, interesting user behavior or even administrative changes. In fact, anything that you can conceive of that could happen to your system could be an interesting scenario to explore if you think there\u2019s a likelihood that it may have an impact on one or more of your system\u2019s Objectives. In our book, \u201dLearning Chaos Engineering\u201d by O'Reilly Media , a couple of ways of exploring the conditions you might want to explore are covered. In addition, when you are designing a Verification you have the all-important framing of the overall Objective to help you. The Objective helps you decide and prioritize what verifications to perform that will give you the most effective insights, not least because you may want to perform the verification in production where there is likely more risk from the exploration. For example, you might decide that you want to verify how your system behaves when: A virtual machine fails A network starts to lose packets A configuration change is made A Kubernetes Pod, or collection of pods, fail A cluster is starved of resources, such as nodes A database begins to respond slowly The list will go on, and you will almost certainly have your own unique conditions that you\u2019re interested in. This is one of the reasons why ChaosIQ is built on top of the free and open source Chaos Toolkit , which makes ChaosIQ an easily customizable and extendable system verification and chaos engineering environment. You need that flexibility, because your conditions will often be unique to your systems. The first thing you describe in a Verification is the types of conditions you want to introduce to see how this affects your system\u2019s behaviour in respect of your overall Objective. A verification then needs a description of how it will be executed. While a verification is running it will be capturing your Objective\u2019s measurements throughout, continuously gathering sample events that indicate whether the measurement was successful or failed in reference to the overall Objective: A Verification needs two pieces of information to run itself: Duration and Frequency of Measurement. Duration is self-explanatory, it\u2019s the total duration that you want the verification to be executed for. For example, you might want to run a Verification as the backdrop to a 3-hour GameDay (More on how to do this in a forthcoming article) so, as you\u2019d expect, you\u2019d set the duration of the Verification in this case to 3 hours. Frequency of Measurement describes just how often you will want to gather a sample event from the system as described by a Measurement for your Objective. You might want to sample every second, or perhaps sampling a measurement every 10 minutes will give you the fidelity you\u2019re looking for. As you run your Verification, all of the data captured by your Measurements\u2019 sample events are collated for interpretation into Insights. Insights When your Verification has been executed the resulting, potentially large, set of data collated from all the sample event measurements is captured and made available to you. This timeline of event samples in its raw form can be useful but the most common first step is to try to assess what impact on your Objective was seen by those measurements during your verification\u2019s execution. This insight is called the \u201cObjective Impact\u201d. The \"Objective Impact\" insight is a calculation based on the duration of the verification and how many failed sample events were measured. The insight gives you an extrapolated indicator of what size of impact the conditions of your verification have on your Objective. This information is key to then decide whether the impact is so minor that your system survived just fine, or whether it\u2019s actually time to assemble your teams and look to the next stage of the workflow: Action Items. Action Items (coming soon) Insights give you the information you and your teams need to decide what to do to improve your system\u2019s reliability. The insights are framed by the objectives you care about and so you have everything you need to be able to understand and prioritize what should be done and when. What should be done and when are Action Items. Action Items are how you describe what system reliability improvements you are going to work on. You describe them in ChaosIQ while you analyze the insights from your Verifications. Then track their progress and eventually impacts on future Verification executions. ChaosIQ integrates with the systems you normally use to capture, prioritize and track your work, i.e. issue trackers. ChaosIQ mirrors Action Items as issues in your regular toolset so you can work on this reliability work and its progress is mirrored back into ChaosIQ. Action Items close the learning loop of the System Verification workflow. Each time you and your teams create new Verifications and explore more and more insights, you will describe and action more reliability improvements balancing your need to innovate at speed with the need to provide a system your users can rely on.","title":"The ChaosIQ Reliability Workflow"},{"location":"reliability-workflow/reliability-workflow/#the-chaosiq-reliability-workflow","text":"ChaosIQ provides a Reliability Workflow. The Reliability Workflow\u2019s job is to help you proactively verify your system to gain insights into its reliability so that you can then prioritize and track work on improving that reliability alongside the regular work that you need to do on features. There are lots of good reasons to verify your system. You might be worried about surprise downtime and looking to try to anticipate and prepare better for incidents. You might also be curious as to how your system might respond to challenging conditions, and want to explore that before your users do. In a nutshell you want to verify your system because you care about your users\u2019 experience, and specifically about the reliability of that experience. With ChaosIQ, the goal of system verification is not only to show the impact that various conditions might have on your users happiness but to also turn those insights into prioritized, meaningful actions for improving a system's reliability. ChaosIQ brings this System Reliability Workflow to life with Objectives, Verifications, Insights and Action Items:","title":"The ChaosIQ Reliability Workflow"},{"location":"reliability-workflow/reliability-workflow/#objectives-and-measurements","text":"Objectives are literally things you care about. If you care about it, and can measure it, then it\u2019s an objective. You might care that your homepage is available 99.9% of the time. You might care that your database is able to respond to a particular query under an amount of time. Or you might care that your users can interact with your system, perform some system function, 99.999% of the time as it\u2019s super-critical! These are all Objectives, and they frame what\u2019s important to you about your system. A good set of Objectives represents a great high-level description of how your system aims to behave, from your perspective, in order to make your users happy. However, an Objective is not particularly useful unless it can be measured. Objectives can be measured in lots of different ways, often in combination, to give you some confidence that an Objective, at a given moment, is being met: The job of a measurement, or combination of measurements, is to be able provide a sample, an event, that is either \"successful\" or \"failing\" at a given moment in time. For example, you might measure that the response time for your homepage is within a tolerable time bracket at a given moment and, if it is within that tolerance, then it is a \"successful\" sample event. If the measurement shows that the homepage URL does not respond in the tolerated time, then the sample event would be designated \"failed\": The combination of Objectives and their corresponding measurements provides a shared understanding of how your system needs to behave in order to keep your users happy. This is the all-important framing necessary to then decide what you want to verify in order to see how your Objectives, and your users\u2019 happiness, is affected by your system\u2019s behavior under various conditions. TBD link to where you can define objectives in the Getting Started.","title":"Objectives and Measurements"},{"location":"reliability-workflow/reliability-workflow/#verifications","text":"Verifying an Objective helps you build trust and confidence in how your system will behave under a set of interesting conditions. Those conditions could be behavior such as security intrusions, infrastructure failures, platform failures, application failures, interesting user behavior or even administrative changes. In fact, anything that you can conceive of that could happen to your system could be an interesting scenario to explore if you think there\u2019s a likelihood that it may have an impact on one or more of your system\u2019s Objectives. In our book, \u201dLearning Chaos Engineering\u201d by O'Reilly Media , a couple of ways of exploring the conditions you might want to explore are covered. In addition, when you are designing a Verification you have the all-important framing of the overall Objective to help you. The Objective helps you decide and prioritize what verifications to perform that will give you the most effective insights, not least because you may want to perform the verification in production where there is likely more risk from the exploration. For example, you might decide that you want to verify how your system behaves when: A virtual machine fails A network starts to lose packets A configuration change is made A Kubernetes Pod, or collection of pods, fail A cluster is starved of resources, such as nodes A database begins to respond slowly The list will go on, and you will almost certainly have your own unique conditions that you\u2019re interested in. This is one of the reasons why ChaosIQ is built on top of the free and open source Chaos Toolkit , which makes ChaosIQ an easily customizable and extendable system verification and chaos engineering environment. You need that flexibility, because your conditions will often be unique to your systems. The first thing you describe in a Verification is the types of conditions you want to introduce to see how this affects your system\u2019s behaviour in respect of your overall Objective. A verification then needs a description of how it will be executed. While a verification is running it will be capturing your Objective\u2019s measurements throughout, continuously gathering sample events that indicate whether the measurement was successful or failed in reference to the overall Objective: A Verification needs two pieces of information to run itself: Duration and Frequency of Measurement. Duration is self-explanatory, it\u2019s the total duration that you want the verification to be executed for. For example, you might want to run a Verification as the backdrop to a 3-hour GameDay (More on how to do this in a forthcoming article) so, as you\u2019d expect, you\u2019d set the duration of the Verification in this case to 3 hours. Frequency of Measurement describes just how often you will want to gather a sample event from the system as described by a Measurement for your Objective. You might want to sample every second, or perhaps sampling a measurement every 10 minutes will give you the fidelity you\u2019re looking for. As you run your Verification, all of the data captured by your Measurements\u2019 sample events are collated for interpretation into Insights.","title":"Verifications"},{"location":"reliability-workflow/reliability-workflow/#insights","text":"When your Verification has been executed the resulting, potentially large, set of data collated from all the sample event measurements is captured and made available to you. This timeline of event samples in its raw form can be useful but the most common first step is to try to assess what impact on your Objective was seen by those measurements during your verification\u2019s execution. This insight is called the \u201cObjective Impact\u201d. The \"Objective Impact\" insight is a calculation based on the duration of the verification and how many failed sample events were measured. The insight gives you an extrapolated indicator of what size of impact the conditions of your verification have on your Objective. This information is key to then decide whether the impact is so minor that your system survived just fine, or whether it\u2019s actually time to assemble your teams and look to the next stage of the workflow: Action Items.","title":"Insights"},{"location":"reliability-workflow/reliability-workflow/#action-items-coming-soon","text":"Insights give you the information you and your teams need to decide what to do to improve your system\u2019s reliability. The insights are framed by the objectives you care about and so you have everything you need to be able to understand and prioritize what should be done and when. What should be done and when are Action Items. Action Items are how you describe what system reliability improvements you are going to work on. You describe them in ChaosIQ while you analyze the insights from your Verifications. Then track their progress and eventually impacts on future Verification executions. ChaosIQ integrates with the systems you normally use to capture, prioritize and track your work, i.e. issue trackers. ChaosIQ mirrors Action Items as issues in your regular toolset so you can work on this reliability work and its progress is mirrored back into ChaosIQ. Action Items close the learning loop of the System Verification workflow. Each time you and your teams create new Verifications and explore more and more insights, you will describe and action more reliability improvements balancing your need to innovate at speed with the need to provide a system your users can rely on.","title":"Action Items (coming soon)"},{"location":"running-on-docker/build-a-custom-docker-image/","text":"It's recommended to use the chaosiq/chaostoolkit Docker image from Docker Hub, which is provided by ChaosIQ. However if you want to build a customer Docker image, so you can add your own extensions the following can be used as a starter for your own Dockerfile: FROM chaostoolkit/chaostoolkit RUN apk update && \\ apk add --virtual build-deps libffi-dev openssl-dev gcc python3-dev musl-dev && \\ pip install --no-cache-dir chaostoolkit-kubernetes && \\ pip install --no-cache-dir chaosiq-cloud && \\ apk del build-deps && \\ rm -rf /tmp/* /root/.cache ADD . /home/svc WORKDIR /home/svc Add the above to a Dockerfile , it can the be built with: docker build -t my/chaostoolkit . With the above Dockerfile we have added the chaostoolkit-kubernetes as an example customization, you can confirm this has been included by running: docker run my/chaostoolkit info extensions You should get an output showing you the Docker image includes the chaostoolkit-kubernetes extension. Once you have built your local Docker image you can use your custom image in place of the ChaosIQ chaosiq/chaostoolkit image. If you are following the section on How to Run with ChaosIQ with Docker just replace chaosiq/chaostoolkit with your custom image name (my/chaostoolkit).","title":"Build a Custom Docker image to use ChaosIQ"},{"location":"running-on-docker/chaosiq-on-docker-intro/","text":"This how to looks at how you can run Chaos Toolkit with ChaosIQ as a Docker image. We are going to use the ChaosIQ chaosiq/chaostoolkit Docker image from Docker Hub, but if you want to build your own custom Docker image it is covered here Build a Custom Docker Image To run with the ChaosIQ chaosiq/chaostoolkit Docker image see: Run an Experiment with Docker Run an Experiment with Docker and ChaosIQ Run an Experiment with Docker and ChaosIQ","title":"Introduction to Docker"},{"location":"running-on-docker/run-experiment/","text":"ChaosIQ Docker image ChaosIQ have made the chaosiq/chaostoolkit Docker image available on docker hub, you can download it with: docker pull chaosiq/chaostoolkit This will make the image available in your own Docker environment. Run an Experiment on the ChaosIQ Docker image The ChaosIQ Docker image uses /home/svc as its working directory, we will use this to pass experiments to the docker image and to share the chaostoolkit.log and the journal.json files with the host. In your working directory create a subdirectory /ctk . You will then be able to execute and experiment with the following command: docker run -e \"ENDPOINT_URL=https://httpstat.us/200?sleep=2000\" \\ -v ` pwd ` /ctk:/home/svc chaosiq/chaostoolkit run \\ https://raw.githubusercontent.com/open-chaos/experiment-catalog/master/local/url-responds/url-responds.json The experiment used is an experiment from the open source Experiment Catalog , its a useful resource to get you started with your own experiments. The experiment we are using simply probes a URL and expects a 200 success response code, the full experiment can be seen in Catalog Url Responds Experiment . The experiment depends on an environment variable ENDPOINT_URL , this is setup with the -e command line argument in the docker run command. We are also using the -v option to mount a shared volume between our local ./ctk subdirectory and the /home/svc directory on the Docker guest. We then specify the image we are going to run and provide some command line arguments, in the above case we use the command run and provide a URL to the experiment. The output from the above command is: [ 2020 -03-25 09 :26:14 INFO ] Validating the experiment 's syntax [2020-03-25 09:26:14 INFO] Experiment looks valid [2020-03-25 09:26:14 INFO] Running experiment: Checks the hypothesis that a URL responds with a 200 status [2020-03-25 09:26:14 INFO] Steady state hypothesis: Application is normal [2020-03-25 09:26:14 INFO] Probe: application-must-respond-normally [2020-03-25 09:26:17 INFO] Steady state hypothesis is met! [2020-03-25 09:26:17 INFO] Action: dummy step [2020-03-25 09:26:17 INFO] Steady state hypothesis: Application is normal [2020-03-25 09:26:17 INFO] Probe: application-must-respond-normally [2020-03-25 09:26:20 INFO] Steady state hypothesis is met! [2020-03-25 09:26:20 INFO] Let' s rollback... [ 2020 -03-25 09 :26:20 INFO ] No declared rollbacks, let ' s move on. [ 2020 -03-25 09 :26:20 INFO ] Experiment ended with status: completed After running docker run command we can check the ./ctk subdirectory and we will find the chaostoolkit.log and the journal.json file. Using a local Experiment file We can also use a local experiment file with this approach. In the ./ctk subdirectory create an experiment.json and paste in a copy of the Url Responds Experiment and save the file. Then run: docker run -e \"ENDPOINT_URL=https://httpstat.us/200?sleep=2000\" \\ -v ` pwd ` /ctk:/home/svc chaosiq/chaostoolkit run experiment.json You will get the same output show above and an updated chaostoolkit.log and a new journal.json in the ./ctk folder.","title":"Run an Experiment with Docker"},{"location":"running-on-docker/run-experiment/#chaosiq-docker-image","text":"ChaosIQ have made the chaosiq/chaostoolkit Docker image available on docker hub, you can download it with: docker pull chaosiq/chaostoolkit This will make the image available in your own Docker environment.","title":"ChaosIQ Docker image"},{"location":"running-on-docker/run-experiment/#run-an-experiment-on-the-chaosiq-docker-image","text":"The ChaosIQ Docker image uses /home/svc as its working directory, we will use this to pass experiments to the docker image and to share the chaostoolkit.log and the journal.json files with the host. In your working directory create a subdirectory /ctk . You will then be able to execute and experiment with the following command: docker run -e \"ENDPOINT_URL=https://httpstat.us/200?sleep=2000\" \\ -v ` pwd ` /ctk:/home/svc chaosiq/chaostoolkit run \\ https://raw.githubusercontent.com/open-chaos/experiment-catalog/master/local/url-responds/url-responds.json The experiment used is an experiment from the open source Experiment Catalog , its a useful resource to get you started with your own experiments. The experiment we are using simply probes a URL and expects a 200 success response code, the full experiment can be seen in Catalog Url Responds Experiment . The experiment depends on an environment variable ENDPOINT_URL , this is setup with the -e command line argument in the docker run command. We are also using the -v option to mount a shared volume between our local ./ctk subdirectory and the /home/svc directory on the Docker guest. We then specify the image we are going to run and provide some command line arguments, in the above case we use the command run and provide a URL to the experiment. The output from the above command is: [ 2020 -03-25 09 :26:14 INFO ] Validating the experiment 's syntax [2020-03-25 09:26:14 INFO] Experiment looks valid [2020-03-25 09:26:14 INFO] Running experiment: Checks the hypothesis that a URL responds with a 200 status [2020-03-25 09:26:14 INFO] Steady state hypothesis: Application is normal [2020-03-25 09:26:14 INFO] Probe: application-must-respond-normally [2020-03-25 09:26:17 INFO] Steady state hypothesis is met! [2020-03-25 09:26:17 INFO] Action: dummy step [2020-03-25 09:26:17 INFO] Steady state hypothesis: Application is normal [2020-03-25 09:26:17 INFO] Probe: application-must-respond-normally [2020-03-25 09:26:20 INFO] Steady state hypothesis is met! [2020-03-25 09:26:20 INFO] Let' s rollback... [ 2020 -03-25 09 :26:20 INFO ] No declared rollbacks, let ' s move on. [ 2020 -03-25 09 :26:20 INFO ] Experiment ended with status: completed After running docker run command we can check the ./ctk subdirectory and we will find the chaostoolkit.log and the journal.json file.","title":"Run an Experiment on the ChaosIQ Docker image"},{"location":"running-on-docker/run-experiment/#using-a-local-experiment-file","text":"We can also use a local experiment file with this approach. In the ./ctk subdirectory create an experiment.json and paste in a copy of the Url Responds Experiment and save the file. Then run: docker run -e \"ENDPOINT_URL=https://httpstat.us/200?sleep=2000\" \\ -v ` pwd ` /ctk:/home/svc chaosiq/chaostoolkit run experiment.json You will get the same output show above and an updated chaostoolkit.log and a new journal.json in the ./ctk folder.","title":"Using a local Experiment file"},{"location":"running-on-docker/run-verification/","text":"Create a Verification Verifications can also run on the Docker image. First you will need to create a Verification. Select Verifications in the ChaosIQ Sidebar, and then select the Create a New Verification button. Select an objective to link the Verification, once an Object has been selected you should see: Select a Frequency and a Duration, for that sake of running a quick Verification, use something like a Frequency of something like 5 seconds and a Duration of 30 seconds. For the purpose of this, leave the No Condition option set and use the default Verification name, then select the Create Verification and View Execution Steps button, you will be take to the Run Verification page: From the Run Verification page, you can Copy the verify command and extract the URL from the command, this can be used in the Run Verification section. Run the Verification A Verification runs using a different runtime pattern from an experiment, it will also populate the Insights view on ChaosIQ, the Run and Verify page details the differences between run and verify . You can then run the Verification with the following command: docker run -v ` pwd ` /ctk:/home/svc -v ` pwd ` /ctk_config:/tmp/settings \\ chaosiq/chaostoolkit --settings /tmp/settings/settings.yaml verify \\ https://console.chaosiq.dev/assets/verifications/e2cd334c-e5f5-4af0-b82c-47e852e9eb95.json Note You should replace the URL in the above command with your own URL obtained from the Run Verification page. When the verification has completed you should be able to go to the ChaosIQ Insights page and see the Insight generated by the Verification execution: You could equally download the Verification by selecting the Download Verification button and save this to the ./ctk in a file called Verification.json . You can then run this file locally as follows: docker run -v ` pwd ` /ctk:/home/svc \\ -v ` pwd ` /ctk_config:/tmp/settings chaosiq/chaostoolkit \\ --settings /tmp/settings/settings.yaml verify verification.json Again the insights will be displayed on ChaosIQ. That\u2019s it! We have covered using the ChaosIQ chaosiq/chaostoolkit Docker image to run simple experiments and verifications. This can be used as the basis on running with Docker in many different environments which we will cover in further ChaosIQ How To docs.","title":"Run a Verification with Docker"},{"location":"running-on-docker/run-verification/#create-a-verification","text":"Verifications can also run on the Docker image. First you will need to create a Verification. Select Verifications in the ChaosIQ Sidebar, and then select the Create a New Verification button. Select an objective to link the Verification, once an Object has been selected you should see: Select a Frequency and a Duration, for that sake of running a quick Verification, use something like a Frequency of something like 5 seconds and a Duration of 30 seconds. For the purpose of this, leave the No Condition option set and use the default Verification name, then select the Create Verification and View Execution Steps button, you will be take to the Run Verification page: From the Run Verification page, you can Copy the verify command and extract the URL from the command, this can be used in the Run Verification section.","title":"Create a Verification"},{"location":"running-on-docker/run-verification/#run-the-verification","text":"A Verification runs using a different runtime pattern from an experiment, it will also populate the Insights view on ChaosIQ, the Run and Verify page details the differences between run and verify . You can then run the Verification with the following command: docker run -v ` pwd ` /ctk:/home/svc -v ` pwd ` /ctk_config:/tmp/settings \\ chaosiq/chaostoolkit --settings /tmp/settings/settings.yaml verify \\ https://console.chaosiq.dev/assets/verifications/e2cd334c-e5f5-4af0-b82c-47e852e9eb95.json Note You should replace the URL in the above command with your own URL obtained from the Run Verification page. When the verification has completed you should be able to go to the ChaosIQ Insights page and see the Insight generated by the Verification execution: You could equally download the Verification by selecting the Download Verification button and save this to the ./ctk in a file called Verification.json . You can then run this file locally as follows: docker run -v ` pwd ` /ctk:/home/svc \\ -v ` pwd ` /ctk_config:/tmp/settings chaosiq/chaostoolkit \\ --settings /tmp/settings/settings.yaml verify verification.json Again the insights will be displayed on ChaosIQ. That\u2019s it! We have covered using the ChaosIQ chaosiq/chaostoolkit Docker image to run simple experiments and verifications. This can be used as the basis on running with Docker in many different environments which we will cover in further ChaosIQ How To docs.","title":"Run the Verification"},{"location":"running-on-docker/run-with-chaosiq/","text":"Running with ChaosIQ To connect the image to ChaosIQ the Chaos Toolkit on hte Docker image will need to be signed in to ChaosIQ. The Signing in to ChaosIQ page describes the sign-in in full. The only difference here is, we will not use the default settings file by using following command for the sign-in step: chaos --settings ` pwd ` /ctk_config/settings.yaml signin The chaos signin will prompt is similar to the following, when the prompt for the token shows, paste in the ChaosIQ token: (chaostk) $ chaos signin ChaosIQ Cloud url [https://console.chaosiq.io]: ChaosIQ Cloud token: Experiments and executions will be published to team 'Staging' in organization 'ChaosIQ' ChaosIQ Cloud details saved at /Users/grant/chaosiq-docker/settings.yaml Note The file path for the settings.yaml in the above will be your local working directory. Run Docker Image with your Settings File Having created the settings file in the ./ctk_config subdirectory you can now run: docker run -e \"ENDPOINT_URL=https://httpstat.us/200?sleep=2000\" \\ -v ` pwd ` /ctk:/home/svc -v ` pwd ` /ctk_config:/tmp/settings chaosiq/chaostoolkit \\ --settings /tmp/settings/settings.yaml run experiment.json Here we setup a volume share with the ./ctk_config subdirectory on the host and /tmp/settings on the guest with the -v option. Then we use the --setttings option with the chaos run command to use those settings. The result of running the command will result in the experiment being published to ChaosIQ. If you login to ChaosIQ and navigate to the Executions page you will see the running execution: If the execution has completed, you can see the completed executions by selecting the Finished tab: If you select the details button on the most recently finished execution, you will see the execution detail: Within the execution detail page if you expand the General label you can see the details of the execution and the Experiment Steady-State Hypothesis which shows the details of the Steady-State Hypothesis.","title":"Run an Experiment with Docker and ChaosIQ"},{"location":"running-on-docker/run-with-chaosiq/#running-with-chaosiq","text":"To connect the image to ChaosIQ the Chaos Toolkit on hte Docker image will need to be signed in to ChaosIQ. The Signing in to ChaosIQ page describes the sign-in in full. The only difference here is, we will not use the default settings file by using following command for the sign-in step: chaos --settings ` pwd ` /ctk_config/settings.yaml signin The chaos signin will prompt is similar to the following, when the prompt for the token shows, paste in the ChaosIQ token: (chaostk) $ chaos signin ChaosIQ Cloud url [https://console.chaosiq.io]: ChaosIQ Cloud token: Experiments and executions will be published to team 'Staging' in organization 'ChaosIQ' ChaosIQ Cloud details saved at /Users/grant/chaosiq-docker/settings.yaml Note The file path for the settings.yaml in the above will be your local working directory.","title":"Running with ChaosIQ"},{"location":"running-on-docker/run-with-chaosiq/#run-docker-image-with-your-settings-file","text":"Having created the settings file in the ./ctk_config subdirectory you can now run: docker run -e \"ENDPOINT_URL=https://httpstat.us/200?sleep=2000\" \\ -v ` pwd ` /ctk:/home/svc -v ` pwd ` /ctk_config:/tmp/settings chaosiq/chaostoolkit \\ --settings /tmp/settings/settings.yaml run experiment.json Here we setup a volume share with the ./ctk_config subdirectory on the host and /tmp/settings on the guest with the -v option. Then we use the --setttings option with the chaos run command to use those settings. The result of running the command will result in the experiment being published to ChaosIQ. If you login to ChaosIQ and navigate to the Executions page you will see the running execution: If the execution has completed, you can see the completed executions by selecting the Finished tab: If you select the details button on the most recently finished execution, you will see the execution detail: Within the execution detail page if you expand the General label you can see the details of the execution and the Experiment Steady-State Hypothesis which shows the details of the Steady-State Hypothesis.","title":"Run Docker Image with your Settings File"},{"location":"running-on-kubernetes/create-experiment-operator/","text":"Now that you setup successfully your operator and your ChaosIQ secrets, we'll show you on how to create the Chaos Experiment definition to pass to the operator. To run Chaos Toolkit with ChaosIQ as a kubernetes pod, we provide a default docker image , but you can create your own, with additional extensions if needed, as described in the documentation . The default image will be downloaded from the docker hub . First, get the asset URL for either the verification or the experiment from the ChaosIQ console. Copy the URL from the chaos command, or right-click on the downlad button to copy the target link. Your verification or experiment URL shall be like the following pattern: https://console.chaosiq.io/assets/[verifications|experiments]/<uuid>.json Then, you shall use the following template, with your own asset URL, to create a Chaos Toolkit Experiment definition. You must modify the command arguments to verify or run an experiment with your own asset URL, update the pod image if you created a custom ChaosIQ docker image , update the settings secret name if desired. You can also customize your manifest following the official documentation . --- apiVersion : chaostoolkit.org/v1 kind : ChaosToolkitExperiment metadata : name : my-chaos-exp namespace : chaostoolkit-crd spec : namespace : chaostoolkit-run pod : image : chaosiq/chaostoolkit chaosArgs : - verify - https://console.chaosiq.io/assets/verifications/134f08a1-7072-4de3-b4bc-ca21486b4c23.json settings : enabled : true secretName : chaostoolkit-settings experiment : asFile : false Save that manifest into a yaml file e.g. verification.yaml . Finally, apply that manifest onto your Kubernetes cluster: $ kubectl apply -f ./verification.yaml You'll be able to handle your experiments in your cluster from the command line, as described in the official documentation . The executions and results of those experiements will be pushed to your ChaosIQ console and visible in the Insights and Executions pages.","title":"Create a Chaos Experiment on Kubernetes"},{"location":"running-on-kubernetes/intro/","text":"Running ChaosIQ Verifications and Experiments from inside a Kubernetes cluster is possible thanks to the open source Chaos Toolkit Kubernetes operator . This allows you to run remotely instead of from the standard command line on local machines. First, you will need to deploy the operator in your cluster. To do so, please refer to the official open source Chaos Toolkit documentation .","title":"Introduction to Kubernetes"},{"location":"running-on-kubernetes/settings-as-secret/","text":"This section explains how to configure and use this operator for running ChaosIQ verifications and experiments. To be able to fetch assets from ChaosIQ, as well as pushing back results, for both experiments and verifications, you'll need to setup a settings file with a valid token and selected targeted organization & team. Please refer to these documentation links, to signin to ChaosIQ with a token and select your default organization and team . By default, the settings file can be located at: ~/.chaostoolkit/settings.yaml Then, you'll need to load these settings into Kubernetes, as a secret: $ kubectl -n chaostoolkit-run \\ create secret generic chaostoolkit-settings \\ --from-file = settings.yaml = ~/.chaostoolkit/settings.yaml Please refer to the official documentation for more information on how to pass settings to the experiment with the operator. You might have multiple organizations and teams, even possibly tokens, to use. In that case, it's best to uniquely name your secret, as example: chaostoolkit-settings-<my-org>-<my-team> This will allow you to use multiple verifications and experiments from various teams within the same namespace in your Kubernetes cluster. However, you'll need to specify the settings secret name to the Chaos Experiment, as described in the documentation .","title":"Configure ChaosIQ settings as secret"},{"location":"running-on-travis/chaosiq-on-travis-intro/","text":"This how to looks at how you can run Chaos Toolkit and ChaosIQ as part of a Travis CI build. If you are new to Continuous Integration (CI) the Travis Core concepts is useful. We are going to run the the Chaos Toolkit as part of a Travis build using Python . To run Chaos Toolkit with and without ChaosIQ see the links below: Prerequisites . Run an Experiment with Travis CI . Run an Experiment with Travis CI and ChaosIQ .","title":"Introduction to Travis"},{"location":"running-on-travis/prerequisites/","text":"To run Chaos Toolkit as part of a Travis CI build a number of prerequisites are required: Chaos Toolkit installed and running on your local machine. If you want to run with ChaosIQ you will need a ChaosIQ account account and a Token for Chaos IQ . A Travis CI account. A Github account (An alternative is to use Bitbucket , but this is not covered here). Owner permissions for a project hosted on Github .","title":"Prerequisites"},{"location":"running-on-travis/run-experiment/","text":"This section covers running a Chaos Toolkit experiment on Travis. If you start with a local working directory, you can push this to a Github repository at a later step to get things running on Travis. Create an Experiment File You will need an experiment to run on Travis so you could use one of your own experiments or you could use the following as a starting point: { \"version\" : \"1.0.0\" , \"title\" : \"Checks the hypothesis that a URL responds with a 200 status\" , \"description\" : \"Check a given url responds with a 200 status\" , \"contributions\" : { \"availability\" : \"none\" , \"reliability\" : \"none\" , \"safety\" : \"none\" , \"security\" : \"none\" , \"performability\" : \"none\" }, \"steady-state-hypothesis\" : { \"title\" : \"Application is normal\" , \"probes\" : [ { \"type\" : \"probe\" , \"name\" : \"application-must-respond-normally\" , \"tolerance\" : 200 , \"provider\" : { \"type\" : \"http\" , \"url\" : \"https://httpstat.us/200?sleep=2000\" , \"timeout\" : 3 } } ] }, \"method\" : [ { \"type\" : \"action\" , \"name\" : \"dummy step\" , \"provider\" : { \"type\" : \"process\" , \"path\" : \"echo\" , \"arguments\" : \"URL used is: https://httpstat.us/200?sleep=2000\" } } ], \"rollbacks\" : [] } The experiment above just checks a URL for a success response. Configure Travis You will need a travis configuration file, the following is a good starting point: language: python python: - \"3.7\" install: - pip install -r requirements.txt script: - chaos run experiment.json Add the above code to the .travis.yaml file. The Travis config file uses Python 3.7 and pip to install dependencies from a requirements.txt file. The following is the initial requirements.txt you can can use: chaostoolkit It will then execute the chaos run command. Run the experiment locally Just to make sure everything is setup correctly run the experiment locally. Create a Python Virtual environment and run: pip install -r requirements.txt Now run the experiment with Chaos Toolkit: chaos run experiment.json When you run the experiment locally you should see output like the following: [2020-03-30 15:26:58 INFO] Validating the experiment's syntax [2020-03-30 15:26:58 INFO] Experiment looks valid [2020-03-30 15:26:58 INFO] Running experiment: Checks the hypothesis that a URL responds with a 200 status [2020-03-30 15:27:02 INFO] Execution available at http://console.chaosiq.io/ChaosIQ/Staging/executions/ae051a93-791a-42f2-8f28-9d054f452ad5 [2020-03-30 15:27:04 INFO] Steady state hypothesis: Application is normal [2020-03-30 15:27:06 INFO] Probe: application-must-respond-normally [2020-03-30 15:27:10 INFO] Steady state hypothesis is met! [2020-03-30 15:27:13 INFO] Action: dummy step [2020-03-30 15:27:16 INFO] Steady state hypothesis: Application is normal [2020-03-30 15:27:18 INFO] Probe: application-must-respond-normally [2020-03-30 15:27:22 INFO] Steady state hypothesis is met! [2020-03-30 15:27:23 INFO] Let's rollback... [2020-03-30 15:27:24 INFO] No declared rollbacks, let's move on. [2020-03-30 15:27:25 INFO] Experiment ended with status: completed This tells you the experiment.json is valid and runs locally and the Steady State Hypothesis is met. Create a Github Repository You will need a Github Repository to run with Travis. Create a repository for your build, you will need to allow Travis to access this repository to run the build. Once you have created your repository link it to your locally working directory using commands something like: git remote add origin git@github.com:gtfisher/travis-test.git In the above command gtfisher is the Github account and travis-test is the Github repository. Configure Travis for your Git Repository You will need to ensure your repository is configured to run with Travis, the Travis CI Tutorial covers this. Push to Github. Now you have Travis configured and activated on your Github repository, you can push your changes to the repository and trigger a build on Travis: git push -u origin master When you have pushed your changes to Github, go to your Travis console and you should, after a brief delay, see a job running a build for your committed changes: This shows your job has been scheduled and the build will start shortly. The build will then run and you will see output like: This shows the output from the Travis job, it shows: Setting up a Python virtual environment The Python version number The pip version number The pip install from requirements.txt The execution of the chaos run experiment.json command The output from the command - this will be similar to the output shown when run locally. We have now gone through the steps to configure and setup and experiment to run with Travis CI with a Github repository.","title":"Run a Chaos Experiment"},{"location":"running-on-travis/run-experiment/#create-an-experiment-file","text":"You will need an experiment to run on Travis so you could use one of your own experiments or you could use the following as a starting point: { \"version\" : \"1.0.0\" , \"title\" : \"Checks the hypothesis that a URL responds with a 200 status\" , \"description\" : \"Check a given url responds with a 200 status\" , \"contributions\" : { \"availability\" : \"none\" , \"reliability\" : \"none\" , \"safety\" : \"none\" , \"security\" : \"none\" , \"performability\" : \"none\" }, \"steady-state-hypothesis\" : { \"title\" : \"Application is normal\" , \"probes\" : [ { \"type\" : \"probe\" , \"name\" : \"application-must-respond-normally\" , \"tolerance\" : 200 , \"provider\" : { \"type\" : \"http\" , \"url\" : \"https://httpstat.us/200?sleep=2000\" , \"timeout\" : 3 } } ] }, \"method\" : [ { \"type\" : \"action\" , \"name\" : \"dummy step\" , \"provider\" : { \"type\" : \"process\" , \"path\" : \"echo\" , \"arguments\" : \"URL used is: https://httpstat.us/200?sleep=2000\" } } ], \"rollbacks\" : [] } The experiment above just checks a URL for a success response.","title":"Create an Experiment File"},{"location":"running-on-travis/run-experiment/#configure-travis","text":"You will need a travis configuration file, the following is a good starting point: language: python python: - \"3.7\" install: - pip install -r requirements.txt script: - chaos run experiment.json Add the above code to the .travis.yaml file. The Travis config file uses Python 3.7 and pip to install dependencies from a requirements.txt file. The following is the initial requirements.txt you can can use: chaostoolkit It will then execute the chaos run command.","title":"Configure Travis"},{"location":"running-on-travis/run-experiment/#run-the-experiment-locally","text":"Just to make sure everything is setup correctly run the experiment locally. Create a Python Virtual environment and run: pip install -r requirements.txt Now run the experiment with Chaos Toolkit: chaos run experiment.json When you run the experiment locally you should see output like the following: [2020-03-30 15:26:58 INFO] Validating the experiment's syntax [2020-03-30 15:26:58 INFO] Experiment looks valid [2020-03-30 15:26:58 INFO] Running experiment: Checks the hypothesis that a URL responds with a 200 status [2020-03-30 15:27:02 INFO] Execution available at http://console.chaosiq.io/ChaosIQ/Staging/executions/ae051a93-791a-42f2-8f28-9d054f452ad5 [2020-03-30 15:27:04 INFO] Steady state hypothesis: Application is normal [2020-03-30 15:27:06 INFO] Probe: application-must-respond-normally [2020-03-30 15:27:10 INFO] Steady state hypothesis is met! [2020-03-30 15:27:13 INFO] Action: dummy step [2020-03-30 15:27:16 INFO] Steady state hypothesis: Application is normal [2020-03-30 15:27:18 INFO] Probe: application-must-respond-normally [2020-03-30 15:27:22 INFO] Steady state hypothesis is met! [2020-03-30 15:27:23 INFO] Let's rollback... [2020-03-30 15:27:24 INFO] No declared rollbacks, let's move on. [2020-03-30 15:27:25 INFO] Experiment ended with status: completed This tells you the experiment.json is valid and runs locally and the Steady State Hypothesis is met.","title":"Run the experiment locally"},{"location":"running-on-travis/run-experiment/#create-a-github-repository","text":"You will need a Github Repository to run with Travis. Create a repository for your build, you will need to allow Travis to access this repository to run the build. Once you have created your repository link it to your locally working directory using commands something like: git remote add origin git@github.com:gtfisher/travis-test.git In the above command gtfisher is the Github account and travis-test is the Github repository.","title":"Create a Github Repository"},{"location":"running-on-travis/run-experiment/#configure-travis-for-your-git-repository","text":"You will need to ensure your repository is configured to run with Travis, the Travis CI Tutorial covers this.","title":"Configure Travis for your Git Repository"},{"location":"running-on-travis/run-experiment/#push-to-github","text":"Now you have Travis configured and activated on your Github repository, you can push your changes to the repository and trigger a build on Travis: git push -u origin master When you have pushed your changes to Github, go to your Travis console and you should, after a brief delay, see a job running a build for your committed changes: This shows your job has been scheduled and the build will start shortly. The build will then run and you will see output like: This shows the output from the Travis job, it shows: Setting up a Python virtual environment The Python version number The pip version number The pip install from requirements.txt The execution of the chaos run experiment.json command The output from the command - this will be similar to the output shown when run locally. We have now gone through the steps to configure and setup and experiment to run with Travis CI with a Github repository.","title":"Push to Github."},{"location":"running-on-travis/run-with-chaosiq/","text":"This section explains how to configure and use Travis for running Chaos Toolkit experiments and publishing the results to ChaosIQ . To be able to fetch assets from ChaosIQ, as well as pushing back results, for both experiments and verifications, you'll need to setup a settings file with a valid token and selected targeted organization & team. Please refer to these documentation links, to signin to ChaosIQ with a token and select your default organization and team . Add the ChaosIQ Extension You will need to add the ChaosIQ extension to the Github repository we setup in the previous section. Open the requirements.txt file and add the line: chaosiq-cloud Then run: pip install -r requirements.txt This will install the plugin which will allow you to generate a settings file to use with Travis. Configure the ChaosIQ Settings You will need to create a settings file to use with our experiment. In your terminal window run: (chaostk) $ chaos --settings ./settings.yaml signin ChaosIQ Cloud url [https://console.chaosiq.io]: ChaosIQ Cloud token: Experiments and executions will be published to team 'Staging' in organization 'ChaosIQ' ChaosIQ Cloud details saved at ./settings.yaml When the signin command prompts for the token paste in your token for ChaosIQ. Warning The settings.yaml contains sensitive information and must not be committed to your Github repository, add it to your .gitignore file now. You can if you wish run your experiment locally to confirm that it will publish your execution to ChaosIQ with the settings file you have configured, if you wish to do this run: chaos --settings settings.yaml run experiment.json You can the login to ChaosIQ Executions page to confirm your execution has been published. Encrypt the Settings File As mentioned above the settings file contains sensitive information and should not be pushed to your Github repository. Travis has a feature to enable you to encrypt a file then use that file as part of you job execution on Travis, this is detailed in the Travis Documentation . Install the Travis CLI To encrypt a file and to use that encrypted file on your Travis build you will need to install the Travis CLI, see the Travis CLI installation instructions. Once installed you will need to use the Travis CLI to login in to your Travis account with the following command: travis login --com You can now encrypt the settings.yaml and the Travis CLI will share the secure encryption variables with you Travis account. Encrypt the settings file with the following command: travis encrypt-file settings.yaml --add --com This will give the following output: encrypting settings.yaml for gtfisher/travis-test storing result as settings.yaml.enc storing secure env variables for decryption Overwrite the config file /Users/grant/dev/try/travis-test/.travis.yml with the content below? This reformats the existing file. --- language: python python: - '3.7' install: - pip install -r requirements.txt script: - chaos run experiment.json before_install: - openssl aes-256-cbc -K $encrypted_fdb844fae20b_key -iv $encrypted_fdb844fae20b_iv -in settings.yaml.enc -out settings.yaml -d (y/N) y Make sure to add settings.yaml.enc to the git repository. Make sure not to add settings.yaml to the git repository. Commit all changes to your .travis.yml. Note In the above output gtfisher is the Travis account name and travis-test is the name of the Github repository. This encrypts the settings.yaml file into settings.yaml.enc , it also setups secure environment variables for decryption and updates the travis config to use those environment variables. You now need to update the chaos run command in the .travis.yml file so it uses the settings.yaml file that will be decrypted from the settings.yaml.enc when the build runs. In the .travis.yml change the chaos run command to: script: - chaos --settings settings.yaml run experiment.json Run the new build on Travis You now need to commit the following files your Github repository: settings.yaml.enc requirements.txt .travis.yml .gitignore This will cause a new build to be triggered. If you go to the Travis console you will see the job executing and eventually the output from the job execution: The output shows at the top the two secure environment variables and shows the output of the experiment running. This includes the information that the experiment will be published to ChaosIQ and lists the URL when the execution is published to. If you navigate to that URL you will see a detailed view of the execution, if you expand the General section and you can confirm the execution is part of a Travis job: Note If you want to run a Verification instead of an experiment all you need to do is add a verification file to the Github repository and change the chaos run command with chaos verify . The Verification will run as part of the Travis build and the results will be published to the Insights view on ChaosIQ. In this section we have: Added the ChaosIQ plugin by updating the requirements.txt . Created a settings.yaml file and encrypted it for use on Travis. Updated the .travis.yaml file to use the encrypted file and change the chaos command to use the settings file. Pushed the changes to the Github repository to trigger a build The build has executed and published the execution on the Executions page on ChaosIQ","title":"Run an Experiment with ChaosIQ"},{"location":"running-on-travis/run-with-chaosiq/#add-the-chaosiq-extension","text":"You will need to add the ChaosIQ extension to the Github repository we setup in the previous section. Open the requirements.txt file and add the line: chaosiq-cloud Then run: pip install -r requirements.txt This will install the plugin which will allow you to generate a settings file to use with Travis.","title":"Add the ChaosIQ Extension"},{"location":"running-on-travis/run-with-chaosiq/#configure-the-chaosiq-settings","text":"You will need to create a settings file to use with our experiment. In your terminal window run: (chaostk) $ chaos --settings ./settings.yaml signin ChaosIQ Cloud url [https://console.chaosiq.io]: ChaosIQ Cloud token: Experiments and executions will be published to team 'Staging' in organization 'ChaosIQ' ChaosIQ Cloud details saved at ./settings.yaml When the signin command prompts for the token paste in your token for ChaosIQ. Warning The settings.yaml contains sensitive information and must not be committed to your Github repository, add it to your .gitignore file now. You can if you wish run your experiment locally to confirm that it will publish your execution to ChaosIQ with the settings file you have configured, if you wish to do this run: chaos --settings settings.yaml run experiment.json You can the login to ChaosIQ Executions page to confirm your execution has been published.","title":"Configure the ChaosIQ Settings"},{"location":"running-on-travis/run-with-chaosiq/#encrypt-the-settings-file","text":"As mentioned above the settings file contains sensitive information and should not be pushed to your Github repository. Travis has a feature to enable you to encrypt a file then use that file as part of you job execution on Travis, this is detailed in the Travis Documentation .","title":"Encrypt the Settings File"},{"location":"running-on-travis/run-with-chaosiq/#install-the-travis-cli","text":"To encrypt a file and to use that encrypted file on your Travis build you will need to install the Travis CLI, see the Travis CLI installation instructions. Once installed you will need to use the Travis CLI to login in to your Travis account with the following command: travis login --com You can now encrypt the settings.yaml and the Travis CLI will share the secure encryption variables with you Travis account. Encrypt the settings file with the following command: travis encrypt-file settings.yaml --add --com This will give the following output: encrypting settings.yaml for gtfisher/travis-test storing result as settings.yaml.enc storing secure env variables for decryption Overwrite the config file /Users/grant/dev/try/travis-test/.travis.yml with the content below? This reformats the existing file. --- language: python python: - '3.7' install: - pip install -r requirements.txt script: - chaos run experiment.json before_install: - openssl aes-256-cbc -K $encrypted_fdb844fae20b_key -iv $encrypted_fdb844fae20b_iv -in settings.yaml.enc -out settings.yaml -d (y/N) y Make sure to add settings.yaml.enc to the git repository. Make sure not to add settings.yaml to the git repository. Commit all changes to your .travis.yml. Note In the above output gtfisher is the Travis account name and travis-test is the name of the Github repository. This encrypts the settings.yaml file into settings.yaml.enc , it also setups secure environment variables for decryption and updates the travis config to use those environment variables. You now need to update the chaos run command in the .travis.yml file so it uses the settings.yaml file that will be decrypted from the settings.yaml.enc when the build runs. In the .travis.yml change the chaos run command to: script: - chaos --settings settings.yaml run experiment.json","title":"Install the Travis CLI"},{"location":"running-on-travis/run-with-chaosiq/#run-the-new-build-on-travis","text":"You now need to commit the following files your Github repository: settings.yaml.enc requirements.txt .travis.yml .gitignore This will cause a new build to be triggered. If you go to the Travis console you will see the job executing and eventually the output from the job execution: The output shows at the top the two secure environment variables and shows the output of the experiment running. This includes the information that the experiment will be published to ChaosIQ and lists the URL when the execution is published to. If you navigate to that URL you will see a detailed view of the execution, if you expand the General section and you can confirm the execution is part of a Travis job: Note If you want to run a Verification instead of an experiment all you need to do is add a verification file to the Github repository and change the chaos run command with chaos verify . The Verification will run as part of the Travis build and the results will be published to the Insights view on ChaosIQ. In this section we have: Added the ChaosIQ plugin by updating the requirements.txt . Created a settings.yaml file and encrypted it for use on Travis. Updated the .travis.yaml file to use the encrypted file and change the chaos command to use the settings file. Pushed the changes to the Github repository to trigger a build The build has executed and published the execution on the Executions page on ChaosIQ","title":"Run the new build on Travis"},{"location":"running-the-cli/cli/","text":"To run experiments and verifications locally you will need to install the Chaos Toolkit, this is covered in the Getting Started section, in the Chaos Toolkit installation page. To run verifications and to use ChaosIQ you will also need the ChaosIQ plugin, again this is covered in the Getting Started section, ChaosIQ Plugin installation . To confirm the Chaos Toolkit and the ChaosIQ extension are installed, open up a terminal window and activate your virtual environment for the Chaos Toolkit and enter chaos --help : Usage: chaos [ OPTIONS ] COMMAND [ ARGS ] ... Options: --version Show the version and exit. --verbose Display debug level traces. --no-version-check Do not search for an updated version of the chaostoolkit. --change-dir TEXT Change directory before running experiment. --no-log-file Disable logging to file entirely. --log-file TEXT File path where to write the command 's log. [default: chaostoolkit.log] --log-format [string|json] Console logging format: string, json. --settings TEXT Path to the settings file. [default: /Users/grant/.chaostoolkit/settings.yaml] --help Show this message and exit. Commands: disable Disable a ChaosIQ feature discover Discover capabilities and experiments. enable Enable a ChaosIQ feature info Display information about the Chaos Toolkit environment. init Initialize a new experiment from discovered capabilities. org Set ChaosIQ organisation publish Publish your experiment' s journal to ChaosIQ run Run the experiment loaded from SOURCE, either a local file or a... signin Sign-in with your ChaosIQ credentials team Set ChaosIQ team validate Validate the experiment at PATH. verify Run the verification loaded from SOURCE, either a local file or... If the output is like the above this confirms you have the Chaos Toolkit and the ChaosIQ extension installed. To run a simple experiment you can use one of the experiments from the Open Chaos Experiment Catalog , such as the UrlRespondsExperiment . This can be run with: ENDPOINT_URL = https://httpstat.us/200?sleep = 2000 \\ chaos run https://raw.githubusercontent.com/open-chaos/experiment-catalog/master/local/url-responds/url-responds.json This should result in output like: 2020 -04-01 10 :40:42 INFO ] Validating the experiment 's syntax [2020-04-01 10:40:42 INFO] Experiment looks valid [2020-04-01 10:40:42 INFO] Running experiment: Checks the hypothesis that a URL responds with a 200 status [2020-04-01 10:40:44 INFO] Execution available at http://console.chaosiq.io/ChaosIQ/Staging/executions/4b10f6c5-a62f-4e52-ba4e-6db0b2cb7bf8 [2020-04-01 10:40:45 INFO] Steady state hypothesis: Application is normal [2020-04-01 10:40:47 INFO] Probe: application-must-respond-normally [2020-04-01 10:40:51 INFO] Steady state hypothesis is met! [2020-04-01 10:40:54 INFO] Action: dummy step [2020-04-01 10:40:56 INFO] Steady state hypothesis: Application is normal [2020-04-01 10:40:59 INFO] Probe: application-must-respond-normally [2020-04-01 10:41:02 INFO] Steady state hypothesis is met! [2020-04-01 10:41:03 INFO] Let' s rollback... [ 2020 -04-01 10 :41:04 INFO ] No declared rollbacks, let ' s move on. [ 2020 -04-01 10 :41:06 INFO ] Experiment ended with status: completed You could equally download the json file from the catalog and run locally with the command: ENDPOINT_URL = https://httpstat.us/200?sleep = 2000 \\ chaos run url-responds.json Run a Verification To run a verification from your local CLI you need to sign-in to ChaosIQ with a token and select your default organization and team . You can then login to ChaosIQ from a browser, ensure you are using the same organization and team. You can either create a new verification from the Verifications page or import an experiment: Here we will go through the steps to import an experiment. Select the Import Experiment button: Either drag your experiment file or select Choose File to navigate to the file in your local directory. The page will show the probes and actions that have been detected in your experiment. The title from your steady-state hypothesis will be used as your objective name. The title from your experiment will be used as your verification name. These can be modified as required. You will then need to populate your objective data where you define your success criteria, this would be something like 98% over 1 day. You will also specify a frequency, as this is just an example verification you can use something like a Frequency of 5 seconds for a duration of 30 seconds. Note For a verifications, more realistic figures would be used. You can then select the Create Verification and View Execution Steps button, this will display the steps required to execute the verification or you can download the verification to run locally. You can use the URL on this page to execute the verification from your terminal, for my verification the command is: ENDPOINT_URL = https://httpstat.us/200?sleep = 2000 \\ chaos verify https://console.chaosiq.dev/assets/verifications/151fa75d-44ad-442d-9e30-de8d91d1cdb4.json Note You will need to modify the above command to use your own URL generated from ChaosIQ. You should see output similar to: [ 2020 -04-01 12 :10:57 INFO ] Validating the experiment 's syntax [2020-04-01 12:10:57 INFO] Experiment looks valid [2020-04-01 12:10:57 INFO] Verification looks valid [2020-04-01 12:10:58 INFO] Execution available at http://console.chaosiq.io/ChaosIQ/Staging/executions/830ad7ae-3ab0-4c56-8e4a-ecb92d6fb08e [2020-04-01 12:10:59 INFO] Started run ' e4b3d029-6754-4253-a830-39d000d976b1 ' of verification ' Checks the hypothesis that a URL responds with a 200 status ' [2020-04-01 12:11:00 INFO] Starting verification warm-up period of None seconds [2020-04-01 12:11:00 INFO] Finished verification warm-up [2020-04-01 12:11:00 INFO] Triggering verification conditions [2020-04-01 12:11:01 INFO] Starting verification measurement every 5 seconds [2020-04-01 12:11:01 INFO] Running verification measurement 1 [2020-04-01 12:11:01 INFO] Steady state hypothesis: Application is normal [2020-04-01 12:11:01 INFO] Probe: application-must-respond-normally [2020-04-01 12:11:03 INFO] Action: dummy step [2020-04-01 12:11:04 INFO] Steady state hypothesis is met! [2020-04-01 12:11:07 INFO] Finished triggering verification conditions [2020-04-01 12:11:07 INFO] Starting verification conditions for 30.0 seconds [2020-04-01 12:11:10 INFO] Running verification measurement 2 [2020-04-01 12:11:10 INFO] Steady state hypothesis: Application is normal [2020-04-01 12:11:10 INFO] Probe: application-must-respond-normally [2020-04-01 12:11:12 INFO] Steady state hypothesis is met! [2020-04-01 12:11:19 INFO] Running verification measurement 3 [2020-04-01 12:11:19 INFO] Steady state hypothesis: Application is normal [2020-04-01 12:11:19 INFO] Probe: application-must-respond-normally [2020-04-01 12:11:21 INFO] Steady state hypothesis is met! [2020-04-01 12:11:27 INFO] Running verification measurement 4 [2020-04-01 12:11:27 INFO] Steady state hypothesis: Application is normal [2020-04-01 12:11:27 INFO] Probe: application-must-respond-normally [2020-04-01 12:11:30 INFO] Steady state hypothesis is met! [2020-04-01 12:11:36 INFO] Running verification measurement 5 [2020-04-01 12:11:36 INFO] Steady state hypothesis: Application is normal [2020-04-01 12:11:36 INFO] Probe: application-must-respond-normally [2020-04-01 12:11:37 INFO] Finished verification conditions duration [2020-04-01 12:11:37 INFO] Starting verification cool-down period of None seconds [2020-04-01 12:11:39 INFO] Finished verification cool-down period [2020-04-01 12:11:39 INFO] Steady state hypothesis is met! [2020-04-01 12:11:46 INFO] Stopping verification measurements. 5 measurements taken [2020-04-01 12:11:46 INFO] Triggering any verification rollbacks [2020-04-01 12:11:46 INFO] Let' s rollback... [ 2020 -04-01 12 :11:47 INFO ] No declared rollbacks, let ' s move on. [ 2020 -04-01 12 :11:48 INFO ] Finished triggering any verification rollbacks [ 2020 -04-01 12 :11:51 INFO ] Finished running verification: Checks the hypothesis that a URL responds with a 200 status View the Verification on the Insights Page When the verification is completed you should see the Verification on the ChaosIQ Insights page . If you select your verification the insights details will be displayed: This page shows the detail of the verification that has been run including a timeline of the measurements taken and any impact seen. In this section we have: Setup the Chaos Toolkit and installed the ChaosIQ plugin. Run a simple experiment locally. We signed the Chaos Toolkit into ChaosIQ. Created a Verification by import an experiment into ChaosIQ. Run the verification locally and published to the results to ChaosIQ.","title":"Running using the CLI"},{"location":"running-the-cli/cli/#run-a-verification","text":"To run a verification from your local CLI you need to sign-in to ChaosIQ with a token and select your default organization and team . You can then login to ChaosIQ from a browser, ensure you are using the same organization and team. You can either create a new verification from the Verifications page or import an experiment: Here we will go through the steps to import an experiment. Select the Import Experiment button: Either drag your experiment file or select Choose File to navigate to the file in your local directory. The page will show the probes and actions that have been detected in your experiment. The title from your steady-state hypothesis will be used as your objective name. The title from your experiment will be used as your verification name. These can be modified as required. You will then need to populate your objective data where you define your success criteria, this would be something like 98% over 1 day. You will also specify a frequency, as this is just an example verification you can use something like a Frequency of 5 seconds for a duration of 30 seconds. Note For a verifications, more realistic figures would be used. You can then select the Create Verification and View Execution Steps button, this will display the steps required to execute the verification or you can download the verification to run locally. You can use the URL on this page to execute the verification from your terminal, for my verification the command is: ENDPOINT_URL = https://httpstat.us/200?sleep = 2000 \\ chaos verify https://console.chaosiq.dev/assets/verifications/151fa75d-44ad-442d-9e30-de8d91d1cdb4.json Note You will need to modify the above command to use your own URL generated from ChaosIQ. You should see output similar to: [ 2020 -04-01 12 :10:57 INFO ] Validating the experiment 's syntax [2020-04-01 12:10:57 INFO] Experiment looks valid [2020-04-01 12:10:57 INFO] Verification looks valid [2020-04-01 12:10:58 INFO] Execution available at http://console.chaosiq.io/ChaosIQ/Staging/executions/830ad7ae-3ab0-4c56-8e4a-ecb92d6fb08e [2020-04-01 12:10:59 INFO] Started run ' e4b3d029-6754-4253-a830-39d000d976b1 ' of verification ' Checks the hypothesis that a URL responds with a 200 status ' [2020-04-01 12:11:00 INFO] Starting verification warm-up period of None seconds [2020-04-01 12:11:00 INFO] Finished verification warm-up [2020-04-01 12:11:00 INFO] Triggering verification conditions [2020-04-01 12:11:01 INFO] Starting verification measurement every 5 seconds [2020-04-01 12:11:01 INFO] Running verification measurement 1 [2020-04-01 12:11:01 INFO] Steady state hypothesis: Application is normal [2020-04-01 12:11:01 INFO] Probe: application-must-respond-normally [2020-04-01 12:11:03 INFO] Action: dummy step [2020-04-01 12:11:04 INFO] Steady state hypothesis is met! [2020-04-01 12:11:07 INFO] Finished triggering verification conditions [2020-04-01 12:11:07 INFO] Starting verification conditions for 30.0 seconds [2020-04-01 12:11:10 INFO] Running verification measurement 2 [2020-04-01 12:11:10 INFO] Steady state hypothesis: Application is normal [2020-04-01 12:11:10 INFO] Probe: application-must-respond-normally [2020-04-01 12:11:12 INFO] Steady state hypothesis is met! [2020-04-01 12:11:19 INFO] Running verification measurement 3 [2020-04-01 12:11:19 INFO] Steady state hypothesis: Application is normal [2020-04-01 12:11:19 INFO] Probe: application-must-respond-normally [2020-04-01 12:11:21 INFO] Steady state hypothesis is met! [2020-04-01 12:11:27 INFO] Running verification measurement 4 [2020-04-01 12:11:27 INFO] Steady state hypothesis: Application is normal [2020-04-01 12:11:27 INFO] Probe: application-must-respond-normally [2020-04-01 12:11:30 INFO] Steady state hypothesis is met! [2020-04-01 12:11:36 INFO] Running verification measurement 5 [2020-04-01 12:11:36 INFO] Steady state hypothesis: Application is normal [2020-04-01 12:11:36 INFO] Probe: application-must-respond-normally [2020-04-01 12:11:37 INFO] Finished verification conditions duration [2020-04-01 12:11:37 INFO] Starting verification cool-down period of None seconds [2020-04-01 12:11:39 INFO] Finished verification cool-down period [2020-04-01 12:11:39 INFO] Steady state hypothesis is met! [2020-04-01 12:11:46 INFO] Stopping verification measurements. 5 measurements taken [2020-04-01 12:11:46 INFO] Triggering any verification rollbacks [2020-04-01 12:11:46 INFO] Let' s rollback... [ 2020 -04-01 12 :11:47 INFO ] No declared rollbacks, let ' s move on. [ 2020 -04-01 12 :11:48 INFO ] Finished triggering any verification rollbacks [ 2020 -04-01 12 :11:51 INFO ] Finished running verification: Checks the hypothesis that a URL responds with a 200 status","title":"Run a Verification"},{"location":"running-the-cli/cli/#view-the-verification-on-the-insights-page","text":"When the verification is completed you should see the Verification on the ChaosIQ Insights page . If you select your verification the insights details will be displayed: This page shows the detail of the verification that has been run including a timeline of the measurements taken and any impact seen. In this section we have: Setup the Chaos Toolkit and installed the ChaosIQ plugin. Run a simple experiment locally. We signed the Chaos Toolkit into ChaosIQ. Created a Verification by import an experiment into ChaosIQ. Run the verification locally and published to the results to ChaosIQ.","title":"View the Verification on the Insights Page"},{"location":"tokens/generate-token/","text":"To be able to fetch assets from ChaosIQ, as well as pushing back results, for both experiments and verifications, you'll need to set-up a settings file with a valid token and selected targeted organization & team. Generate a Token A token is generated from the ChaosIQ Tokens page . Enter a token name and click the Generate Token button: Click the Copy To Clipboard button and the token will be copied to your clipboard, ready to be added to your Chaos Toolkit CLI by signing in to ChaosIQ.","title":"Tokens"},{"location":"tokens/generate-token/#generate-a-token","text":"A token is generated from the ChaosIQ Tokens page . Enter a token name and click the Generate Token button: Click the Copy To Clipboard button and the token will be copied to your clipboard, ready to be added to your Chaos Toolkit CLI by signing in to ChaosIQ.","title":"Generate a Token"},{"location":"verifications-and-experiments/execution-profile/","text":"An Experiment has a different execution profile from a Verification. When an Experiment runs it will run the Steady State Hypothesis at the beginning of the Experiment. It will then execute the method block in the experiment, followed by running the Steady State Hypothesis again. A Verification on the other hand will execute in exactly the same way as the Experiment, except during the execution of the method block it will continue to run the Steady State Hypothesis at the specified frequency and for the specified duration given in the Verification extension block. In both cases if there are any rollbacks defined these will be executed after the last Steady State Hypothesis is run.","title":"Execution Profile"},{"location":"verifications-and-experiments/experiment-format/","text":"Experiments are fully defined as part of the Chaos Toolkit documentation","title":"Experiment Format"},{"location":"verifications-and-experiments/introduction/","text":"The Chaos Toolkit aims to give you the simplest experience for writing and running your own Chaos Engineering experiments. The main concepts are all expressed in an experiment definition, this has now been extended to support Verifications. Experiment Format Verification Format Execution Profile Experiment and Verification Execution","title":"Introduction"},{"location":"verifications-and-experiments/run-and-verify/","text":"The Chaos Toolkit supports a number of commands and options, if you have Chaos Toolkit installed, execute the chaos command, you will see output like: Usage: chaos [ OPTIONS ] COMMAND [ ARGS ] ... Options: --version Show the version and exit. --verbose Display debug level traces. --no-version-check Do not search for an updated version of the chaostoolkit. --change-dir TEXT Change directory before running experiment. --no-log-file Disable logging to file entirely. --log-file TEXT File path where to write the command ' s log. [ default: chaostoolkit.log ] --log-format [ string | json ] Console logging format: string, json. --settings TEXT Path to the settings file. [ default: /Users/grant/.chaostoolkit/settings.yaml ] --help Show this message and exit. Commands: discover Discover capabilities and experiments. info Display information about the Chaos Toolkit environment. init Initialize a new experiment from discovered capabilities. run Run the experiment loaded from SOURCE, either a local file or a... validate Validate the experiment at PATH. This shows the core Chaos Toolkit support for the chaos run command. To add the ability to run Verifications and to publish the results to ChaosIQ you need to install the ChaosIQ Plugin . Once the plugin is installed run the chaos command again and you will see: Usage: chaos [ OPTIONS ] COMMAND [ ARGS ] ... Options: --version Show the version and exit. --verbose Display debug level traces. --no-version-check Do not search for an updated version of the chaostoolkit. --change-dir TEXT Change directory before running experiment. --no-log-file Disable logging to file entirely. --log-file TEXT File path where to write the command 's log. [default: chaostoolkit.log] --log-format [string|json] Console logging format: string, json. --settings TEXT Path to the settings file. [default: /Users/grant/.chaostoolkit/settings.yaml] --help Show this message and exit. Commands: disable Disable a ChaosIQ feature discover Discover capabilities and experiments. enable Enable a ChaosIQ feature info Display information about the Chaos Toolkit environment. init Initialize a new experiment from discovered capabilities. org Set ChaosIQ organisation publish Publish your experiment' s journal to ChaosIQ run Run the experiment loaded from SOURCE, either a local file or a... signin Sign-in with your ChaosIQ credentials team Set ChaosIQ team validate Validate the experiment at PATH. verify Run the verification loaded from SOURCE, either a local file or... The ChaosIQ plugin adds some additional commands to the core Chaos Toolkit CLI, this includes commands to signin to ChaosIQ and the command to verify . You now have availalbe chaos run to run an Experiment and chaos verify to run a Verification. The execution is different for both. Chaos Run the chaos run command will execute the experiment given as the SOURCE parameter, an experiment can be specified either a local file or a HTTP resource: ENDPOINT_URL = https://httpstat.us/200?sleep = 2000 ; \\ chaos run https://raw.githubusercontent.com/open-chaos/experiment-catalog/master/local/url-responds/url-responds.json will give output similar to: [ 2020 -03-18 10 :21:26 INFO ] Validating the experiment 's syntax [2020-03-18 10:21:26 INFO] Experiment looks valid [2020-03-18 10:21:26 INFO] Running experiment: Checks the hypothesis that a URL responds with a 200 status [2020-03-18 10:21:28 INFO] Execution available at http://console.chaosiq.dev/ChaosIQ/Staging/executions/6f38b6c5-cf44-4dec-a7b5-7ec6ee03352a [2020-03-18 10:21:29 INFO] Steady state hypothesis: Application is normal [2020-03-18 10:21:31 INFO] Probe: application-must-respond-normally [2020-03-18 10:21:35 INFO] Steady state hypothesis is met! [2020-03-18 10:21:38 INFO] Action: dummy step [2020-03-18 10:21:40 INFO] Steady state hypothesis: Application is normal [2020-03-18 10:21:43 INFO] Probe: application-must-respond-normally [2020-03-18 10:21:46 INFO] Steady state hypothesis is met! [2020-03-18 10:21:47 INFO] Let' s rollback... [ 2020 -03-18 10 :21:49 INFO ] No declared rollbacks, let ' s move on. [ 2020 -03-18 10 :21:50 INFO ] Experiment ended with status: completed If that same experiment is stored locally in a file e.g. url-responds.json , it can be executed as: ENDPOINT_URL = https://httpstat.us/200?sleep = 2000 ; \\ chaos run url-responds.json The output will be the same as shown above, the only difference is when the chaos run is provided with a URL it downloads the experiment from the HTTP resource first. The execution then performs the following steps: Validate the experiment and if it is syntactically valid it will run it. The steady state hypothesis is checked. Execute any methods in the experiment (the experiment can include an array of methods). The steady state hypothesis is then checked again. Finally if there are any rollbacks then these are executed. When connected to ChaosIQ the result of running an Experiment can be seen on the Executions pages: If you select the details button for your Experiment can view the detail of the execution: If you expand the Experiment Steady-State Hypothesis you can see the Steady-State used: Chaos Verify The chaos verify command is added to the Chaos Toolkit CLI by the ChaosIQ plugin. A chaos verify command will execute the verification provided the SOURCE parameter. A verification can be specified either a local file or a HTTP resource: chaos verify https://console.chaosiq.dev/assets/verifications/13e11c55-8fd9-4737-b43f-b62ea763cc6f.json If that same verification is downloaded and stored locally in a file e.g. verify-staging-dummy-action.json , it can be executed as: chaos verify verify-staging-dummy-action.json The output is similar for both commands: [ 2020 -03-18 12 :40:30 INFO ] Validating the experiment 's syntax [2020-03-18 12:40:30 INFO] Experiment looks valid [2020-03-18 12:40:30 INFO] Verification looks valid [2020-03-18 12:40:31 INFO] Execution available at http://console.chaosiq.dev/ChaosIQ/Staging/executions/68158971-8ed1-45fd-815c-a92233c402f9 [2020-03-18 12:40:33 INFO] Started run ' 8a99aadf-f9b9-4053-8a3f-ad4cb76ed55c ' of verification ' Staging Console should respond within 500 milliseconds with a dummy condition applied. ' [2020-03-18 12:40:34 INFO] Starting verification warm-up period of None seconds [2020-03-18 12:40:34 INFO] Finished verification warm-up [2020-03-18 12:40:34 INFO] Triggering verification conditions [2020-03-18 12:40:35 INFO] Starting verification measurement every 3 seconds [2020-03-18 12:40:35 INFO] Running verification measurement 1 [2020-03-18 12:40:35 INFO] Steady state hypothesis: Staging Console should respond within 500 milliseconds [2020-03-18 12:40:35 INFO] Probe: http-response-time [2020-03-18 12:40:35 INFO] Steady state hypothesis is met! [2020-03-18 12:40:37 INFO] Action: dummy step [2020-03-18 12:40:39 INFO] Running verification measurement 2 [2020-03-18 12:40:39 INFO] Steady state hypothesis: Staging Console should respond within 500 milliseconds [2020-03-18 12:40:39 INFO] Probe: http-response-time [2020-03-18 12:40:39 INFO] Steady state hypothesis is met! [2020-03-18 12:40:40 INFO] Finished triggering verification conditions [2020-03-18 12:40:40 INFO] Starting verification conditions for 10 seconds [2020-03-18 12:40:43 INFO] Running verification measurement 3 [2020-03-18 12:40:43 INFO] Steady state hypothesis: Staging Console should respond within 500 milliseconds [2020-03-18 12:40:43 INFO] Probe: http-response-time [2020-03-18 12:40:44 INFO] Steady state hypothesis is met! [2020-03-18 12:40:48 INFO] Running verification measurement 4 [2020-03-18 12:40:48 INFO] Steady state hypothesis: Staging Console should respond within 500 milliseconds [2020-03-18 12:40:48 INFO] Probe: http-response-time [2020-03-18 12:40:48 INFO] Steady state hypothesis is met! [2020-03-18 12:40:50 INFO] Finished verification conditions duration [2020-03-18 12:40:50 INFO] Starting verification cool-down period of None seconds [2020-03-18 12:40:52 INFO] Finished verification cool-down period [2020-03-18 12:40:53 INFO] Stopping verification measurements. 4 measurements taken [2020-03-18 12:40:53 INFO] Triggering any verification rollbacks [2020-03-18 12:40:53 INFO] Let' s rollback... [ 2020 -03-18 12 :40:54 INFO ] No declared rollbacks, let ' s move on. [ 2020 -03-18 12 :40:55 INFO ] Finished triggering any verification rollbacks [ 2020 -03-18 12 :40:57 INFO ] Finished running verification: Staging Console should respond within 500 milliseconds with a dummy condition applied. The only difference is when the chaos verify is provided with an HTTP resource, it downloads the verification first. The execution then performs the following steps: Validate the verification/experiment is syntactically correct and if it is valid it will run it. The steady state hypothesis is checked. Execute any methods in the verification. The steady state hypothesis is then checked again. Then a process is started that will execute the Steady State Hypothesis at the frequency-of-measurement defined in the Verification, for the duration-of-conditions (in the case above it takes a measurement every 3 seconds for a period of 10 seconds). Finally if there are any rollbacks then these are executed. When connected to ChaosIQ the result of running a Verification can be seen on the insights page: If you select the details button for your Verification can view the detail of the Verification execution: The details view includes information about the Objective, the Measurement used and the Verification. It shows the Verification Run Timeline that includes a timeline chart of samples.","title":"Experiment and Verification Execution"},{"location":"verifications-and-experiments/run-and-verify/#chaos-run","text":"the chaos run command will execute the experiment given as the SOURCE parameter, an experiment can be specified either a local file or a HTTP resource: ENDPOINT_URL = https://httpstat.us/200?sleep = 2000 ; \\ chaos run https://raw.githubusercontent.com/open-chaos/experiment-catalog/master/local/url-responds/url-responds.json will give output similar to: [ 2020 -03-18 10 :21:26 INFO ] Validating the experiment 's syntax [2020-03-18 10:21:26 INFO] Experiment looks valid [2020-03-18 10:21:26 INFO] Running experiment: Checks the hypothesis that a URL responds with a 200 status [2020-03-18 10:21:28 INFO] Execution available at http://console.chaosiq.dev/ChaosIQ/Staging/executions/6f38b6c5-cf44-4dec-a7b5-7ec6ee03352a [2020-03-18 10:21:29 INFO] Steady state hypothesis: Application is normal [2020-03-18 10:21:31 INFO] Probe: application-must-respond-normally [2020-03-18 10:21:35 INFO] Steady state hypothesis is met! [2020-03-18 10:21:38 INFO] Action: dummy step [2020-03-18 10:21:40 INFO] Steady state hypothesis: Application is normal [2020-03-18 10:21:43 INFO] Probe: application-must-respond-normally [2020-03-18 10:21:46 INFO] Steady state hypothesis is met! [2020-03-18 10:21:47 INFO] Let' s rollback... [ 2020 -03-18 10 :21:49 INFO ] No declared rollbacks, let ' s move on. [ 2020 -03-18 10 :21:50 INFO ] Experiment ended with status: completed If that same experiment is stored locally in a file e.g. url-responds.json , it can be executed as: ENDPOINT_URL = https://httpstat.us/200?sleep = 2000 ; \\ chaos run url-responds.json The output will be the same as shown above, the only difference is when the chaos run is provided with a URL it downloads the experiment from the HTTP resource first. The execution then performs the following steps: Validate the experiment and if it is syntactically valid it will run it. The steady state hypothesis is checked. Execute any methods in the experiment (the experiment can include an array of methods). The steady state hypothesis is then checked again. Finally if there are any rollbacks then these are executed. When connected to ChaosIQ the result of running an Experiment can be seen on the Executions pages: If you select the details button for your Experiment can view the detail of the execution: If you expand the Experiment Steady-State Hypothesis you can see the Steady-State used:","title":"Chaos Run"},{"location":"verifications-and-experiments/run-and-verify/#chaos-verify","text":"The chaos verify command is added to the Chaos Toolkit CLI by the ChaosIQ plugin. A chaos verify command will execute the verification provided the SOURCE parameter. A verification can be specified either a local file or a HTTP resource: chaos verify https://console.chaosiq.dev/assets/verifications/13e11c55-8fd9-4737-b43f-b62ea763cc6f.json If that same verification is downloaded and stored locally in a file e.g. verify-staging-dummy-action.json , it can be executed as: chaos verify verify-staging-dummy-action.json The output is similar for both commands: [ 2020 -03-18 12 :40:30 INFO ] Validating the experiment 's syntax [2020-03-18 12:40:30 INFO] Experiment looks valid [2020-03-18 12:40:30 INFO] Verification looks valid [2020-03-18 12:40:31 INFO] Execution available at http://console.chaosiq.dev/ChaosIQ/Staging/executions/68158971-8ed1-45fd-815c-a92233c402f9 [2020-03-18 12:40:33 INFO] Started run ' 8a99aadf-f9b9-4053-8a3f-ad4cb76ed55c ' of verification ' Staging Console should respond within 500 milliseconds with a dummy condition applied. ' [2020-03-18 12:40:34 INFO] Starting verification warm-up period of None seconds [2020-03-18 12:40:34 INFO] Finished verification warm-up [2020-03-18 12:40:34 INFO] Triggering verification conditions [2020-03-18 12:40:35 INFO] Starting verification measurement every 3 seconds [2020-03-18 12:40:35 INFO] Running verification measurement 1 [2020-03-18 12:40:35 INFO] Steady state hypothesis: Staging Console should respond within 500 milliseconds [2020-03-18 12:40:35 INFO] Probe: http-response-time [2020-03-18 12:40:35 INFO] Steady state hypothesis is met! [2020-03-18 12:40:37 INFO] Action: dummy step [2020-03-18 12:40:39 INFO] Running verification measurement 2 [2020-03-18 12:40:39 INFO] Steady state hypothesis: Staging Console should respond within 500 milliseconds [2020-03-18 12:40:39 INFO] Probe: http-response-time [2020-03-18 12:40:39 INFO] Steady state hypothesis is met! [2020-03-18 12:40:40 INFO] Finished triggering verification conditions [2020-03-18 12:40:40 INFO] Starting verification conditions for 10 seconds [2020-03-18 12:40:43 INFO] Running verification measurement 3 [2020-03-18 12:40:43 INFO] Steady state hypothesis: Staging Console should respond within 500 milliseconds [2020-03-18 12:40:43 INFO] Probe: http-response-time [2020-03-18 12:40:44 INFO] Steady state hypothesis is met! [2020-03-18 12:40:48 INFO] Running verification measurement 4 [2020-03-18 12:40:48 INFO] Steady state hypothesis: Staging Console should respond within 500 milliseconds [2020-03-18 12:40:48 INFO] Probe: http-response-time [2020-03-18 12:40:48 INFO] Steady state hypothesis is met! [2020-03-18 12:40:50 INFO] Finished verification conditions duration [2020-03-18 12:40:50 INFO] Starting verification cool-down period of None seconds [2020-03-18 12:40:52 INFO] Finished verification cool-down period [2020-03-18 12:40:53 INFO] Stopping verification measurements. 4 measurements taken [2020-03-18 12:40:53 INFO] Triggering any verification rollbacks [2020-03-18 12:40:53 INFO] Let' s rollback... [ 2020 -03-18 12 :40:54 INFO ] No declared rollbacks, let ' s move on. [ 2020 -03-18 12 :40:55 INFO ] Finished triggering any verification rollbacks [ 2020 -03-18 12 :40:57 INFO ] Finished running verification: Staging Console should respond within 500 milliseconds with a dummy condition applied. The only difference is when the chaos verify is provided with an HTTP resource, it downloads the verification first. The execution then performs the following steps: Validate the verification/experiment is syntactically correct and if it is valid it will run it. The steady state hypothesis is checked. Execute any methods in the verification. The steady state hypothesis is then checked again. Then a process is started that will execute the Steady State Hypothesis at the frequency-of-measurement defined in the Verification, for the duration-of-conditions (in the case above it takes a measurement every 3 seconds for a period of 10 seconds). Finally if there are any rollbacks then these are executed. When connected to ChaosIQ the result of running a Verification can be seen on the insights page: If you select the details button for your Verification can view the detail of the Verification execution: The details view includes information about the Objective, the Measurement used and the Verification. It shows the Verification Run Timeline that includes a timeline chart of samples.","title":"Chaos Verify"},{"location":"verifications-and-experiments/verification-format/","text":"The Verification format is an experiment format that has the addition of an Extension . An example Verification extension is: \"extensions\" : [ { \"name\" : \"chaosiq\" , \"objective_id\" : \"48637aae-11a0-4f16-816f-55faef12d5d0\" , \"verification\" : { \"id\" : \"2adfd65c-ba38-4482-a73e-eb26252e4ebc\" , \"duration-of-conditions\" : 180 , \"frequency-of-measurement\" : 2 }, \"experiment_id\" : \"338e26f6-6ff6-42f8-a181-e7df9cbf385e\" } ] The extension identifies chaosiq as the vendor and then provides a number of custom properties: objective_id: this provides a mapping from the Verification to an Objective. verification: the Verification includes a number of further properties: id: a unique identifier for the Verification. duration-of-condition: this is the deration for the Verification in seconds, this is how long the Verification will run for frequency-of-measurement: this is the frequency that the measurement will be taken at, in this case the measure will be taken at every 2 seconds. The steady state hypothesis in the experiment is used as the measurement. Example Verification { \"title\" : \"Staging console can survive real pod death\" , \"description\" : \"N/A\" , \"configuration\" : {}, \"secrets\" : {}, \"extensions\" : [ { \"name\" : \"chaosiq\" , \"objective_id\" : \"48637aae-11a0-4f16-816f-55faef12d5d0\" , \"verification\" : { \"id\" : \"2adfd65c-ba38-4482-a73e-eb26252e4ebc\" , \"duration-of-conditions\" : 180 , \"frequency-of-measurement\" : 2 }, \"experiment_id\" : \"338e26f6-6ff6-42f8-a181-e7df9cbf385e\" } ], \"tags\" : [], \"steady-state-hypothesis\" : { \"title\" : \"Staging Console is Available\" , \"probes\" : [ { \"name\" : \"http-response-time\" , \"type\" : \"probe\" , \"provider\" : { \"type\" : \"python\" , \"module\" : \"chaoscloud.probes.http\" , \"func\" : \"time_http_call\" , \"arguments\" : { \"url\" : \"https://console.chaosiq.dev\" } }, \"tolerance\" : { \"name\" : \"http-response-time-under\" , \"type\" : \"probe\" , \"provider\" : { \"type\" : \"python\" , \"module\" : \"chaoscloud.tolerances.http\" , \"func\" : \"response_time_under\" , \"arguments\" : { \"duration\" : 500 } } } } ] }, \"method\" : [ { \"name\" : \"terminate-pods\" , \"type\" : \"action\" , \"provider\" : { \"type\" : \"python\" , \"module\" : \"chaosk8s.pod.actions\" , \"func\" : \"terminate_pods\" , \"arguments\" : { \"ns\" : \"chaosiq-console\" , \"label_selector\" : \"chaosiq-saas-backend-6755597d54-8npfz\" , \"all\" : false , \"qty\" : 1 , \"rand\" : false } } } ] } In the full verification above: The verifications title and description are meant for humans and therefore should be as descriptive as possible to clarify the verifications rationale. Configuration and Secrets are optional and is same as for for an Experiment Configuration and Experiment Secrets . Steady State Hypothesis - this is used in this case as a measure of your system. Method - this is used to apply some condition to your system, in this case this is to kill a kubernetes pod.","title":"Verification Format"},{"location":"verifications-and-experiments/verification-format/#example-verification","text":"{ \"title\" : \"Staging console can survive real pod death\" , \"description\" : \"N/A\" , \"configuration\" : {}, \"secrets\" : {}, \"extensions\" : [ { \"name\" : \"chaosiq\" , \"objective_id\" : \"48637aae-11a0-4f16-816f-55faef12d5d0\" , \"verification\" : { \"id\" : \"2adfd65c-ba38-4482-a73e-eb26252e4ebc\" , \"duration-of-conditions\" : 180 , \"frequency-of-measurement\" : 2 }, \"experiment_id\" : \"338e26f6-6ff6-42f8-a181-e7df9cbf385e\" } ], \"tags\" : [], \"steady-state-hypothesis\" : { \"title\" : \"Staging Console is Available\" , \"probes\" : [ { \"name\" : \"http-response-time\" , \"type\" : \"probe\" , \"provider\" : { \"type\" : \"python\" , \"module\" : \"chaoscloud.probes.http\" , \"func\" : \"time_http_call\" , \"arguments\" : { \"url\" : \"https://console.chaosiq.dev\" } }, \"tolerance\" : { \"name\" : \"http-response-time-under\" , \"type\" : \"probe\" , \"provider\" : { \"type\" : \"python\" , \"module\" : \"chaoscloud.tolerances.http\" , \"func\" : \"response_time_under\" , \"arguments\" : { \"duration\" : 500 } } } } ] }, \"method\" : [ { \"name\" : \"terminate-pods\" , \"type\" : \"action\" , \"provider\" : { \"type\" : \"python\" , \"module\" : \"chaosk8s.pod.actions\" , \"func\" : \"terminate_pods\" , \"arguments\" : { \"ns\" : \"chaosiq-console\" , \"label_selector\" : \"chaosiq-saas-backend-6755597d54-8npfz\" , \"all\" : false , \"qty\" : 1 , \"rand\" : false } } } ] } In the full verification above: The verifications title and description are meant for humans and therefore should be as descriptive as possible to clarify the verifications rationale. Configuration and Secrets are optional and is same as for for an Experiment Configuration and Experiment Secrets . Steady State Hypothesis - this is used in this case as a measure of your system. Method - this is used to apply some condition to your system, in this case this is to kill a kubernetes pod.","title":"Example Verification"}]}